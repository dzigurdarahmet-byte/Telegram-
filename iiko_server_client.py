"""
iiko Server API –∫–ª–∏–µ–Ω—Ç (–ª–æ–∫–∞–ª—å–Ω—ã–π)
–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–ª–∞ (–∑–∞–∫–∞–∑—ã —Å—Ç–æ–ª–æ–≤, OLAP, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏)

–°–¢–†–ê–¢–ï–ì–ò–Ø: –ù–µ—Å–∫–æ–ª—å–∫–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö OLAP-–∑–∞–ø—Ä–æ—Å–æ–≤ –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ.
–≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ–±—Ä–µ–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Å—Ç—Ä–æ–∫.
"""

import hashlib
import httpx
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import Optional
from collections import defaultdict
import logging
import json
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

logger = logging.getLogger(__name__)


class IikoServerClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è iikoServer API"""

    def __init__(self, server_url: str, login: str, password: str):
        self.server_url = server_url.rstrip("/")
        self.login = login
        self.password = password
        self.password_hash = hashlib.sha1(password.encode('utf-8')).hexdigest()
        self.token: Optional[str] = None
        self.token_time: Optional[datetime] = None
        self.client = httpx.AsyncClient(timeout=60.0, verify=False)

    async def _ensure_token(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω"""
        if self.token and self.token_time and (datetime.now() - self.token_time).seconds < 600:
            return
        response = await self.client.get(
            f"{self.server_url}/resto/api/auth",
            params={"login": self.login, "pass": self.password_hash}
        )
        response.raise_for_status()
        self.token = response.text.strip().strip('"')
        self.token_time = datetime.now()
        logger.info("iikoServer token –ø–æ–ª—É—á–µ–Ω")

    async def _get(self, endpoint: str, params: dict = None) -> str:
        """GET-–∑–∞–ø—Ä–æ—Å"""
        await self._ensure_token()
        if params is None:
            params = {}
        params["key"] = self.token
        response = await self.client.get(
            f"{self.server_url}{endpoint}", params=params
        )
        response.raise_for_status()
        return response.text

    # ‚îÄ‚îÄ‚îÄ OLAP-–∑–∞–ø—Ä–æ—Å—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def _olap_request(self, date_from: str, date_to: str,
                            group_fields: list, aggregate_fields: list,
                            extra_filters: dict = None) -> list:
        """
        –û–¥–∏–Ω OLAP-–∑–∞–ø—Ä–æ—Å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (dict).
        """
        await self._ensure_token()

        filters = {
            "OpenDate.Typed": {
                "filterType": "DateRange",
                "periodType": "CUSTOM",
                "from": date_from,
                "to": date_to,
                "includeLow": "true",
                "includeHigh": "true"
            }
        }
        if extra_filters:
            filters.update(extra_filters)

        json_body = {
            "reportType": "SALES",
            "buildSummary": "false",
            "groupByRowFields": group_fields,
            "groupByColFields": [],
            "aggregateFields": aggregate_fields,
            "filters": filters
        }

        response = await self.client.post(
            f"{self.server_url}/resto/api/v2/reports/olap",
            params={"key": self.token},
            json=json_body
        )
        logger.info(f"OLAP [{','.join(group_fields)}]: status={response.status_code}, len={len(response.text)}")
        response.raise_for_status()

        return self._parse_olap_response(response.text)

    def _parse_olap_response(self, text: str) -> list:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å OLAP-–æ—Ç–≤–µ—Ç –≤ —Å–ø–∏—Å–æ–∫ dict"""
        text = text.strip()
        if not text:
            return []

        # JSON
        if text.startswith("{") or text.startswith("["):
            try:
                data = json.loads(text)
                if isinstance(data, list):
                    return data
                if isinstance(data, dict):
                    for key in ["data", "rows", "records", "items", "result"]:
                        if key in data and isinstance(data[key], list):
                            return data[key]
                    return [data] if data else []
            except json.JSONDecodeError:
                pass

        # XML
        if text.startswith("<"):
            return self._parse_xml_rows(text)

        # CSV/TSV
        if "\t" in text:
            return self._parse_tsv_rows(text)

        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç OLAP: {text[:200]}")
        return []

    def _parse_xml_rows(self, xml_text: str) -> list:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å XML"""
        try:
            root = ET.fromstring(xml_text)
        except ET.ParseError:
            return []
        rows = []
        for tag in [".//row", ".//record", ".//item", ".//r"]:
            found = root.findall(tag)
            if found:
                for row in found:
                    row_data = {}
                    for child in row:
                        row_data[child.tag] = child.text
                    if row.attrib:
                        row_data.update(row.attrib)
                    if row_data:
                        rows.append(row_data)
                break
        if not rows:
            for elem in root.iter():
                if elem.attrib and elem.tag not in ['olap', 'report', 'result', 'response']:
                    rows.append(dict(elem.attrib))
        return rows

    def _parse_tsv_rows(self, text: str) -> list:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å TSV"""
        lines = text.strip().split("\n")
        if len(lines) < 2:
            return []
        headers = lines[0].split("\t")
        rows = []
        for line in lines[1:]:
            if line.strip():
                values = line.split("\t")
                row = dict(zip(headers, values))
                rows.append(row)
        return rows

    # ‚îÄ‚îÄ‚îÄ –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_olap_report(self, date_from: str, date_to: str,
                              report_type: str = "SALES") -> str:
        """
        –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw —Ç–µ–∫—Å—Ç.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥.
        """
        await self._ensure_token()
        json_body = {
            "reportType": report_type,
            "buildSummary": "false",
            "groupByRowFields": ["OpenDate.Typed"],
            "groupByColFields": [],
            "aggregateFields": [
                "DishDiscountSumInt", "DishAmountInt",
                "DishSumInt", "UniqOrderId.OrdersCount"
            ],
            "filters": {
                "OpenDate.Typed": {
                    "filterType": "DateRange",
                    "periodType": "CUSTOM",
                    "from": date_from,
                    "to": date_to,
                    "includeLow": "true",
                    "includeHigh": "true"
                }
            }
        }
        response = await self.client.post(
            f"{self.server_url}/resto/api/v2/reports/olap",
            params={"key": self.token},
            json=json_body
        )
        response.raise_for_status()
        return response.text

    async def get_sales_data(self, date_from: str, date_to: str) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö ‚Äî –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            # –ó–∞–ø—Ä–æ—Å 1: –ø–æ –¥–Ω—è–º (‚âà25 —Å—Ç—Ä–æ–∫) ‚Äî –æ—Å–Ω–æ–≤–Ω—ã–µ –∏—Ç–æ–≥–∏
            day_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["OpenDate.Typed"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"–ü–æ –¥–Ω—è–º: {len(day_rows)} —Å—Ç—Ä–æ–∫")

            # –ó–∞–ø—Ä–æ—Å 2: –ø–æ –æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∞–º (‚âà10-20 —Å—Ç—Ä–æ–∫)
            waiter_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["OrderWaiter.Name"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"–ü–æ –æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∞–º: {len(waiter_rows)} —Å—Ç—Ä–æ–∫")

            # –ó–∞–ø—Ä–æ—Å 3: –ø–æ —á–∞—Å–∞–º (‚âà15-20 —Å—Ç—Ä–æ–∫)
            hour_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["HourOpen"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"–ü–æ —á–∞—Å–∞–º: {len(hour_rows)} —Å—Ç—Ä–æ–∫")

            # –ó–∞–ø—Ä–æ—Å 4: –ø–æ –±–ª—é–¥–∞–º (‚âà100-200 —Å—Ç—Ä–æ–∫)
            dish_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["DishName", "DishGroup"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt"]
            )
            logger.info(f"–ü–æ –±–ª—é–¥–∞–º: {len(dish_rows)} —Å—Ç—Ä–æ–∫")

            return {
                "day_rows": day_rows,
                "waiter_rows": waiter_rows,
                "hour_rows": hour_rows,
                "dish_rows": dish_rows,
                "multi_query": True
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ OLAP: {e}")
            return {"error": str(e)}

    async def get_period_totals(self, date_from: str, date_to: str) -> dict:
        """–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Ç–æ–≥–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥: {revenue, orders, avg_check}"""
        data = await self.get_sales_data(date_from, date_to)
        if "error" in data:
            return {"revenue": 0, "orders": 0, "avg_check": 0}

        total_revenue = 0
        total_orders = 0
        for row in data.get("day_rows", []):
            total_revenue += float(
                row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0
            )
            total_orders += float(
                row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0
            )

        avg_check = total_revenue / total_orders if total_orders > 0 else 0
        return {
            "revenue": total_revenue,
            "orders": int(total_orders),
            "avg_check": avg_check,
        }

    # ‚îÄ‚îÄ‚îÄ –î–æ—Å—Ç–∞–≤–∫–∞ –∏–∑ OLAP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è OrderServiceType –¥–ª—è –¥–æ—Å—Ç–∞–≤–∫–∏
    DELIVERY_TYPES = {
        "–¥–æ—Å—Ç–∞–≤–∫–∞ –∫—É—Ä—å–µ—Ä–æ–º", "–¥–æ—Å—Ç–∞–≤–∫–∞ —Å–∞–º–æ–≤—ã–≤–æ–∑", "–¥–æ—Å—Ç–∞–≤–∫–∞",
        "delivery_by_courier", "delivery_pickup", "delivery",
    }

    def _is_delivery_row(self, row: dict) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ OLAP –∑–∞–∫–∞–∑–æ–º –¥–æ—Å—Ç–∞–≤–∫–∏"""
        stype = (
            row.get("OrderServiceType")
            or row.get("–¢–∏–ø –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è")
            or row.get("–¢–∏–ø –∑–∞–∫–∞–∑–∞")
            or ""
        ).strip().lower()
        return stype in self.DELIVERY_TYPES

    async def get_delivery_sales_data(self, date_from: str, date_to: str) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –¥–æ—Å—Ç–∞–≤–∫–µ –∏–∑ OLAP ‚Äî –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø—É –∑–∞–∫–∞–∑–∞"""
        try:
            # –ó–∞–ø—Ä–æ—Å: –ø–æ –¥–Ω—è–º + —Ç–∏–ø –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
            day_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["OpenDate.Typed", "OrderServiceType"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"OLAP –¥–æ—Å—Ç–∞–≤–∫–∞ –ø–æ –¥–Ω—è–º: {len(day_rows)} —Å—Ç—Ä–æ–∫")

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–∞–≤–∫—É
            delivery_rows = [r for r in day_rows if self._is_delivery_row(r)]
            logger.info(f"  –∏–∑ –Ω–∏—Ö –¥–æ—Å—Ç–∞–≤–∫–∞: {len(delivery_rows)} —Å—Ç—Ä–æ–∫")

            # –ï—Å–ª–∏ –Ω–µ—Ç —Å—Ç—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏, –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ —Ç–∏–ø—ã
            if not delivery_rows and day_rows:
                types = set()
                for r in day_rows:
                    t = r.get("OrderServiceType") or r.get("–¢–∏–ø –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è") or r.get("–¢–∏–ø –∑–∞–∫–∞–∑–∞") or "?"
                    types.add(t)
                logger.info(f"  –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã: {types}")

            # –ó–∞–ø—Ä–æ—Å: –±–ª—é–¥–∞ –¥–æ—Å—Ç–∞–≤–∫–∏
            dish_rows = []
            if delivery_rows:
                try:
                    all_dish_rows = await self._olap_request(
                        date_from, date_to,
                        group_fields=["DishName", "DishGroup", "OrderServiceType"],
                        aggregate_fields=["DishDiscountSumInt", "DishAmountInt"]
                    )
                    dish_rows = [r for r in all_dish_rows if self._is_delivery_row(r)]
                except Exception as e:
                    logger.warning(f"OLAP –¥–æ—Å—Ç–∞–≤–∫–∞ –±–ª—é–¥–∞: {e}")

            return {
                "day_rows": delivery_rows,
                "dish_rows": dish_rows,
                "all_types_rows": day_rows,  # –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            }

        except Exception as e:
            logger.error(f"OLAP –¥–æ—Å—Ç–∞–≤–∫–∞ –æ—à–∏–±–∫–∞: {e}")
            return {"error": str(e)}

    async def get_delivery_period_totals(self, date_from: str, date_to: str) -> dict:
        """–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Ç–æ–≥–∏ –¥–æ—Å—Ç–∞–≤–∫–∏: {revenue, orders, avg_check}"""
        data = await self.get_delivery_sales_data(date_from, date_to)
        if "error" in data:
            return {"revenue": 0, "orders": 0, "avg_check": 0}

        total_revenue = 0
        total_orders = 0
        for row in data.get("day_rows", []):
            total_revenue += float(
                row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0
            )
            total_orders += float(
                row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0
            )

        avg_check = total_revenue / total_orders if total_orders > 0 else 0
        return {
            "revenue": total_revenue,
            "orders": int(total_orders),
            "avg_check": avg_check,
        }

    async def get_delivery_sales_summary(self, date_from: str, date_to: str) -> str:
        """–°–≤–æ–¥–∫–∞ –ø—Ä–æ–¥–∞–∂ –¥–æ—Å—Ç–∞–≤–∫–∏ –∏–∑ OLAP –¥–ª—è Claude"""
        data = await self.get_delivery_sales_data(date_from, date_to)

        if "error" in data:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞–≤–∫–∏: {data['error']}"

        day_rows = data.get("day_rows", [])
        if not day_rows:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ —Ç–∏–ø—ã –≤–æ–æ–±—â–µ –µ—Å—Ç—å
            all_rows = data.get("all_types_rows", [])
            types = set()
            for r in all_rows:
                t = r.get("OrderServiceType") or r.get("–¢–∏–ø –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è") or "?"
                types.add(t)
            return (
                f"üì¶ –î–æ—Å—Ç–∞–≤–∫–∞ ({date_from} ‚Äî {date_to}): –∑–∞–∫–∞–∑–æ–≤ –¥–æ—Å—Ç–∞–≤–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\n"
                f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã –∑–∞–∫–∞–∑–æ–≤ –≤ OLAP: {', '.join(sorted(types))}"
            )

        total_revenue = 0
        total_revenue_full = 0
        total_qty = 0
        total_orders = 0
        day_stats = {}

        for row in day_rows:
            date = row.get("OpenDate.Typed") or row.get("–£—á–µ—Ç–Ω—ã–π –¥–µ–Ω—å") or ""
            revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
            revenue_full = float(row.get("DishSumInt") or row.get("–°—É–º–º–∞ –±–µ–∑ —Å–∫–∏–¥–∫–∏") or 0)
            qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
            orders = float(row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0)

            total_revenue += revenue
            total_revenue_full += revenue_full
            total_qty += qty
            total_orders += orders

            if date:
                if date not in day_stats:
                    day_stats[date] = {"revenue": 0, "orders": 0, "qty": 0}
                day_stats[date]["revenue"] += revenue
                day_stats[date]["orders"] += orders
                day_stats[date]["qty"] += qty

        lines = [
            f"üì¶ === –î–û–°–¢–ê–í–ö–ê ‚Äî OLAP ({date_from} ‚Äî {date_to}) ===",
            f"–í—ã—Ä—É—á–∫–∞ (—Å–æ —Å–∫–∏–¥–∫–æ–π): {total_revenue:.0f} —Ä—É–±.",
            f"–í—ã—Ä—É—á–∫–∞ (–±–µ–∑ —Å–∫–∏–¥–∫–∏): {total_revenue_full:.0f} —Ä—É–±.",
            f"–ó–∞–∫–∞–∑–æ–≤: {total_orders:.0f}",
            f"–ë–ª—é–¥ –ø—Ä–æ–¥–∞–Ω–æ: {total_qty:.0f} —à—Ç",
        ]
        if total_orders > 0:
            lines.append(f"–°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {total_revenue / total_orders:.0f} —Ä—É–±.")

        if day_stats:
            lines.append("")
            lines.append("–ü–æ –¥–Ω—è–º:")
            for day in sorted(day_stats.keys()):
                d = day_stats[day]
                lines.append(f"  {day} | {d['revenue']:.0f} —Ä—É–±. | {d['orders']:.0f} –∑–∞–∫–∞–∑–æ–≤")

        # –¢–æ–ø –±–ª—é–¥ –¥–æ—Å—Ç–∞–≤–∫–∏
        dish_rows = data.get("dish_rows", [])
        if dish_rows:
            lines.append("")
            lines.append("–¢–æ–ø –±–ª—é–¥ –¥–æ—Å—Ç–∞–≤–∫–∏:")
            dish_list = []
            for row in dish_rows:
                name = row.get("DishName") or row.get("–ë–ª—é–¥–æ") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                dish_list.append({"name": name, "qty": qty, "revenue": revenue})

            for d in sorted(dish_list, key=lambda x: x["revenue"], reverse=True)[:20]:
                lines.append(f"  {d['name']} | {d['qty']:.0f} —à—Ç | {d['revenue']:.0f} —Ä—É–±.")

        return "\n".join(lines)

    # ‚îÄ‚îÄ‚îÄ –°–≤–æ–¥–∫–∞ –¥–ª—è Claude ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_sales_summary(self, date_from: str, date_to: str) -> str:
        """–°–≤–æ–¥–∫–∞ –ø—Ä–æ–¥–∞–∂ –∑–∞–ª–∞ ‚Äî —Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        data = await self.get_sales_data(date_from, date_to)

        if "error" in data:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–ª–∞: {data['error']}"

        lines = ["üìä === –î–ê–ù–ù–´–ï –ó–ê–õ–ê (iikoServer) ==="]

        # ‚îÄ‚îÄ‚îÄ –ò—Ç–æ–≥–∏ –ø–æ –¥–Ω—è–º ‚îÄ‚îÄ‚îÄ
        day_rows = data.get("day_rows", [])
        total_revenue = 0
        total_revenue_full = 0
        total_qty = 0
        total_orders = 0

        day_stats = {}
        for row in day_rows:
            date = row.get("OpenDate.Typed") or row.get("–£—á–µ—Ç–Ω—ã–π –¥–µ–Ω—å") or ""
            revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
            revenue_full = float(row.get("DishSumInt") or row.get("–°—É–º–º–∞ –±–µ–∑ —Å–∫–∏–¥–∫–∏") or 0)
            qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
            orders = float(row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0)

            total_revenue += revenue
            total_revenue_full += revenue_full
            total_qty += qty
            total_orders += orders

            if date:
                day_stats[date] = {
                    "revenue": revenue, "revenue_full": revenue_full,
                    "qty": qty, "orders": orders
                }

        lines.append(f"–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞ –∑–∞–ª–∞ (—Å–æ —Å–∫–∏–¥–∫–æ–π): {total_revenue:.0f} —Ä—É–±.")
        lines.append(f"–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞ –∑–∞–ª–∞ (–±–µ–∑ —Å–∫–∏–¥–∫–∏): {total_revenue_full:.0f} —Ä—É–±.")
        lines.append(f"–í—Å–µ–≥–æ –∑–∞–∫–∞–∑–æ–≤: {total_orders:.0f}")
        lines.append(f"–í—Å–µ–≥–æ –ø—Ä–æ–¥–∞–Ω–æ: {total_qty:.0f} —à—Ç")
        if total_orders > 0:
            lines.append(f"–°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {total_revenue / total_orders:.0f} —Ä—É–±.")
        lines.append(f"–°—Ç—Ä–æ–∫ –ø–æ –¥–Ω—è–º: {len(day_rows)}")
        lines.append("")

        # ‚îÄ‚îÄ‚îÄ –ü–æ –¥–Ω—è–º ‚îÄ‚îÄ‚îÄ
        if day_stats:
            lines.append("–ü–æ –¥–Ω—è–º:")
            for day, stats in sorted(day_stats.items()):
                lines.append(f"  {day} | {stats['revenue']:.0f} —Ä—É–±. | {stats['orders']:.0f} –∑–∞–∫–∞–∑–æ–≤")

        # ‚îÄ‚îÄ‚îÄ –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ ‚îÄ‚îÄ‚îÄ
        waiter_rows = data.get("waiter_rows", [])
        if waiter_rows:
            lines.append("")
            lines.append("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏:")
            waiter_list = []
            for row in waiter_rows:
                name = row.get("OrderWaiter.Name") or row.get("–û—Ñ–∏—Ü–∏–∞–Ω—Ç –∑–∞–∫–∞–∑–∞") or "?"
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                orders = float(row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0)
                waiter_list.append({"name": name, "revenue": revenue, "orders": orders})

            for w in sorted(waiter_list, key=lambda x: x["revenue"], reverse=True):
                avg_check = w["revenue"] / w["orders"] if w["orders"] > 0 else 0
                lines.append(f"  {w['name']} | {w['revenue']:.0f} —Ä—É–±. | {w['orders']:.0f} –∑–∞–∫–∞–∑–æ–≤ | —Å—Ä.—á–µ–∫ {avg_check:.0f}")

        # ‚îÄ‚îÄ‚îÄ –ü–æ —á–∞—Å–∞–º ‚îÄ‚îÄ‚îÄ
        hour_rows = data.get("hour_rows", [])
        if hour_rows:
            lines.append("")
            lines.append("–ü–æ —á–∞—Å–∞–º:")
            hour_list = []
            for row in hour_rows:
                hour = row.get("HourOpen") or row.get("–ß–∞—Å –æ—Ç–∫—Ä—ã—Ç–∏—è") or ""
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                hour_list.append({"hour": hour, "revenue": revenue})

            for h in sorted(hour_list, key=lambda x: x["hour"]):
                lines.append(f"  {h['hour']}:00 | {h['revenue']:.0f} —Ä—É–±.")

        # ‚îÄ‚îÄ‚îÄ –¢–æ–ø –±–ª—é–¥ ‚îÄ‚îÄ‚îÄ
        dish_rows = data.get("dish_rows", [])
        if dish_rows:
            lines.append("")
            lines.append(f"–ü—Ä–æ–¥–∞–∂–∏ –ø–æ –±–ª—é–¥–∞–º (–≤—Å–µ–≥–æ {len(dish_rows)} –ø–æ–∑–∏—Ü–∏–π):")
            dish_list = []
            for row in dish_rows:
                name = row.get("DishName") or row.get("–ë–ª—é–¥–æ") or "?"
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                dish_list.append({"name": name, "group": group, "revenue": revenue, "qty": qty})

            for d in sorted(dish_list, key=lambda x: x["revenue"], reverse=True)[:30]:
                lines.append(f"  {d['name']} | {d['qty']:.0f} —à—Ç | {d['revenue']:.0f} —Ä—É–±. | {d['group']}")

        return "\n".join(lines)

    async def get_products(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Å —Å–µ—Ä–≤–µ—Ä–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç {id: name, sku: name}"""
        result = {}
        try:
            text = await self._get("/resto/api/v2/entities/products/list")
            data = json.loads(text) if text.strip().startswith("[") or text.strip().startswith("{") else []
            if isinstance(data, dict):
                data = data.get("data") or data.get("items") or data.get("products") or []
            for p in data:
                name = p.get("name") or p.get("title") or ""
                if not name:
                    continue
                if p.get("id"):
                    result[p["id"]] = name
                for key in ["code", "sku", "num", "article"]:
                    val = p.get(key)
                    if val:
                        result[val] = name
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ã —Å —Å–µ—Ä–≤–µ—Ä–∞: {e}")
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
            try:
                text = await self._get("/resto/api/products")
                if text.strip().startswith("<"):
                    root = ET.fromstring(text)
                    for p in root.findall(".//*"):
                        name = p.findtext("name") or p.get("name", "")
                        pid = p.findtext("id") or p.get("id", "")
                        code = p.findtext("code") or p.get("code", "")
                        if name and pid:
                            result[pid] = name
                        if name and code:
                            result[code] = name
                elif text.strip().startswith("["):
                    for p in json.loads(text):
                        name = p.get("name", "")
                        if name:
                            if p.get("id"):
                                result[p["id"]] = name
                            if p.get("code"):
                                result[p["code"]] = name
            except Exception as e2:
                logger.warning(f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
        return result

    async def get_product_groups(self) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            text = await self._get("/resto/api/v2/entities/products/group/list")
            data = json.loads(text) if text.strip() else []
            if isinstance(data, dict):
                data = data.get("data") or data.get("items") or data.get("groups") or []
            groups = []
            for g in data:
                name = g.get("name") or g.get("title") or ""
                gid = g.get("id", "")
                parent = g.get("parentId") or g.get("parent", "")
                if name:
                    groups.append({"id": gid, "name": name, "parent": parent})
            return groups
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≥—Ä—É–ø–ø—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {e}")
            return []

    async def get_employees(self) -> list:
        """–°–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        try:
            text = await self._get("/resto/api/employees")
            if text.strip().startswith("["):
                return json.loads(text)
            root = ET.fromstring(text)
            employees = []
            for emp in root.findall(".//employee"):
                name = emp.findtext("name") or ""
                if name:
                    employees.append({"name": name, "id": emp.findtext("id") or ""})
            return employees
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")
            return []

    async def get_roles_debug(self) -> str:
        """–û—Ç–ª–∞–¥–∫–∞: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–æ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        lines = []

        # –í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —Ä–æ–ª–∏ –ø—Ä—è–º–æ –∏–∑ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        try:
            text = await self._get("/resto/api/employees")
            root = ET.fromstring(text)
            role_employees = {}
            for emp in root.findall(".//employee"):
                deleted = emp.findtext("deleted") or "false"
                if deleted == "true":
                    continue
                name = emp.findtext("name") or "?"
                code = emp.findtext("mainRoleCode") or "?"
                if code not in role_employees:
                    role_employees[code] = []
                role_employees[code].append(name)

            lines.append(f"–î–æ–ª–∂–Ω–æ—Å—Ç–∏ (–∏–∑ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤):")
            for code, names in sorted(role_employees.items()):
                lines.append(f"\n  [{code}] ‚Äî {len(names)} —á–µ–ª:")
                for n in names[:10]:
                    lines.append(f"    ‚Ä¢ {n}")
                if len(names) > 10:
                    lines.append(f"    ... –µ—â—ë {len(names) - 10}")
        except Exception as e:
            lines.append(f"–û—à–∏–±–∫–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")

        # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Ä–æ–ª–µ–π
        role_endpoints = [
            "/resto/api/corporation/roles",
            "/resto/api/roles",
        ]
        for ep in role_endpoints:
            try:
                text = await self._get(ep)
                lines.append(f"\n{ep}: {text[:500]}")
            except Exception:
                pass

        return "\n".join(lines)

    async def get_employees_debug(self) -> str:
        """–û—Ç–ª–∞–¥–∫–∞: –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        try:
            text = await self._get("/resto/api/employees")
            # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã—Ö 2 –∑–∞–ø–∏—Å–∏
            if text.strip().startswith("["):
                data = json.loads(text)
                sample = data[:2] if len(data) > 2 else data
                return f"JSON ({len(data)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤):\n" + json.dumps(sample, ensure_ascii=False, indent=2, default=str)[:3800]
            elif text.strip().startswith("<"):
                return f"XML (–ø–µ—Ä–≤—ã–µ 3000 —Å–∏–º–≤–æ–ª–æ–≤):\n{text[:3000]}"
            return text[:3000]
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {e}"

    # ‚îÄ‚îÄ‚îÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–≤–∞—Ä–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_cook_staff_data(self, cook_role_codes: list = None) -> dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–≤–∞—Ä–æ–≤ –∏ –∏—Ö –∑–∞—Ä–ø–ª–∞—Ç—ã –∏–∑ iiko.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"cooks": [...], "avg_salary": float, "count": int}
        """
        result = {"cooks": [], "avg_salary": 0, "count": 0, "source": ""}

        try:
            text = await self._get("/resto/api/employees")
            root = ET.fromstring(text)

            # –í—Å–µ –ø–æ–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ ‚Äî –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            all_fields = set()
            for emp in root.findall(".//employee"):
                for child in emp:
                    all_fields.add(child.tag)
            result["available_fields"] = sorted(all_fields)

            # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–≤–∞—Ä–æ–≤
            for emp in root.findall(".//employee"):
                deleted = emp.findtext("deleted") or "false"
                if deleted == "true":
                    continue

                role_code = (emp.findtext("mainRoleCode") or "").strip()
                name = emp.findtext("name") or "?"

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø–æ–≤–∞—Ä –ª–∏ —ç—Ç–æ
                is_cook = False
                if cook_role_codes:
                    is_cook = role_code.lower() in [c.lower() for c in cook_role_codes]
                else:
                    # –ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç –ø–æ —Ç–∏–ø–∏—á–Ω—ã–º –∫–æ–¥–∞–º/–Ω–∞–∑–≤–∞–Ω–∏—è–º
                    role_lower = role_code.lower()
                    cook_keywords = ["cook", "–ø–æ–≤–∞—Ä", "—à–µ—Ñ", "chef", "–∫—É—Ö–Ω", "kitchen"]
                    is_cook = any(kw in role_lower for kw in cook_keywords)

                if not is_cook:
                    continue

                # –ò—â–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É –≤–æ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–ª—è—Ö
                salary = 0
                salary_field = ""
                salary_fields = [
                    "wage", "salary", "shiftSalary", "ratePerShift",
                    "ratePerHour", "baseSalary", "payRate",
                    "mainRateValue", "rateValue", "rate",
                ]
                for field in salary_fields:
                    val = emp.findtext(field)
                    if val:
                        try:
                            salary = float(val)
                            salary_field = field
                            break
                        except (ValueError, TypeError):
                            pass

                result["cooks"].append({
                    "name": name,
                    "role": role_code,
                    "salary": salary,
                    "salary_field": salary_field,
                })

            # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –∑–∞—Ä–ø–ª–∞—Ç—É
            cooks_with_salary = [c for c in result["cooks"] if c["salary"] > 0]
            result["count"] = len(result["cooks"])
            if cooks_with_salary:
                result["avg_salary"] = sum(c["salary"] for c in cooks_with_salary) / len(cooks_with_salary)
                result["source"] = f"iiko (–ø–æ–ª–µ: {cooks_with_salary[0]['salary_field']})"
            else:
                result["source"] = "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ iiko"

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–≤–∞—Ä–æ–≤: {e}")
            result["error"] = str(e)

        return result

    def _xml_to_text(self, elem, indent=0) -> list:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ—á—å –≤—Å–µ –ø–æ–ª—è –∏–∑ XML-—ç–ª–µ–º–µ–Ω—Ç–∞"""
        lines = []
        prefix = "  " * indent
        for child in elem:
            text = (child.text or "").strip()
            has_children = len(list(child)) > 0
            if has_children:
                lines.append(f"{prefix}{child.tag}:")
                lines.extend(self._xml_to_text(child, indent + 1))
            elif text and len(text) < 300:
                lines.append(f"{prefix}{child.tag}: {text}")
        return lines

    async def get_cook_schedule_debug(self, cook_role_codes: list = None) -> str:
        """–û—Ç–ª–∞–¥–∫–∞: –ø–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –æ —Å–º–µ–Ω–∞—Ö/–ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç–∏ –ø–æ–≤–∞—Ä–æ–≤ –≤ iiko"""
        lines = []
        yesterday = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
        today = datetime.now().strftime("%Y-%m-%d")
        await self._ensure_token()

        # ‚ïê‚ïê‚ïê 1. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è/–ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç–∏ ‚ïê‚ïê‚ïê
        lines.append("‚ïê‚ïê‚ïê –≠–ù–î–ü–û–ò–ù–¢–´ –†–ê–°–ü–ò–°–ê–ù–ò–Ø/–°–ú–ï–ù ‚ïê‚ïê‚ïê")
        schedule_endpoints = [
            "/resto/api/v2/schedule/events",
            "/resto/api/v2/schedule/resultingSchedule",
            "/resto/api/v2/schedule/attendances",
            "/resto/api/v2/employees/sessions",
            "/resto/api/schedules",
            "/resto/api/v2/catering/schedule",
            f"/resto/api/v2/schedule/events?from={yesterday}&to={today}",
            f"/resto/api/v2/schedule/resultingSchedule?from={yesterday}&to={today}",
        ]
        for ep in schedule_endpoints:
            try:
                text = await self._get(ep)
                preview = text[:500].replace("\n", " ")
                lines.append(f"‚úÖ {ep}:\n  {preview}")
            except Exception as e:
                lines.append(f"‚ùå {ep}: {str(e)[:80]}")

        # ‚ïê‚ïê‚ïê 2. OLAP: –∏—â–µ–º –ø–æ–ª—è —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å–æ —Å–º–µ–Ω–∞–º–∏/—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ ‚ïê‚ïê‚ïê
        lines.append("\n‚ïê‚ïê‚ïê OLAP: –ü–û–õ–Ø –°–û–¢–†–£–î–ù–ò–ö–û–í/–°–ú–ï–ù ‚ïê‚ïê‚ïê")
        try:
            response = await self.client.get(
                f"{self.server_url}/resto/api/v2/reports/olap/columns",
                params={"key": self.token, "reportType": "SALES"}
            )
            if response.status_code == 200:
                data = json.loads(response.text)
                field_names = sorted(data.keys()) if isinstance(data, dict) else []
                # –ò—â–µ–º –ø–æ–ª—è —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å–æ —Å–º–µ–Ω–∞–º–∏, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏, –ø–æ—Å–µ—â–∞–µ–º–æ—Å—Ç—å—é
                kw = ["session", "user", "waiter", "employee", "cook",
                      "shift", "attend", "open", "close", "cashier",
                      "—Å–º–µ–Ω", "—Å–æ—Ç—Ä—É–¥", "–ø–æ–≤–∞—Ä", "–∫–∞—Å—Å–∏—Ä", "–æ—Ñ–∏—Ü–∏"]
                found = [f for f in field_names if any(k in f.lower() for k in kw)]
                lines.append(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π: {len(found)}")
                for f in found:
                    lines.append(f"  ‚Ä¢ {f}")
        except Exception as e:
            lines.append(f"–û—à–∏–±–∫–∞: {e}")

        # ‚ïê‚ïê‚ïê 3. OLAP: –ø—Ä–æ–±—É–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∫–∞–∂–¥–æ–º—É –Ω–∞–π–¥–µ–Ω–Ω–æ–º—É –ø–æ–ª—é —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ + –¥–µ–Ω—å ‚ïê‚ïê‚ïê
        lines.append("\n‚ïê‚ïê‚ïê OLAP: –ü–†–û–ë–£–ï–ú –ü–û–õ–Ø –°–û–¢–†–£–î–ù–ò–ö–û–í –ü–û –î–ù–Ø–ú ‚ïê‚ïê‚ïê")
        user_fields = [
            "OpenUser.Name", "SessionUser.Name", "CloseUser.Name",
            "CashRegisterUser.Name", "OrderWaiter.Name",
            "Cooking.Name", "OrderCookingUser.Name",
        ]
        for field in user_fields:
            try:
                rows = await self._olap_request(
                    yesterday, today,
                    group_fields=[field, "OpenDate.Typed"],
                    aggregate_fields=["DishAmountInt"]
                )
                if rows:
                    # –°—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø–æ –¥–Ω—è–º
                    by_day = defaultdict(set)
                    for row in rows:
                        name = row.get(field) or "?"
                        day = row.get("OpenDate.Typed") or "?"
                        by_day[day].add(name)
                    day_info = ", ".join([f"{d}: {len(names)} —á–µ–ª" for d, names in sorted(by_day.items())])
                    all_names = set()
                    for names in by_day.values():
                        all_names.update(names)
                    lines.append(f"‚úÖ {field}: {len(all_names)} —É–Ω–∏–∫. | {day_info}")
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–º–µ–Ω–∞
                    for name in sorted(all_names)[:10]:
                        lines.append(f"    - {name}")
                else:
                    lines.append(f"‚ö™ {field}: –ø—É—Å—Ç–æ")
            except Exception as e:
                lines.append(f"‚ùå {field}: {str(e)[:60]}")

        # ‚ïê‚ïê‚ïê 4. –°–ø–∏—Å–æ–∫ –ø–æ–≤–∞—Ä–æ–≤ –∏–∑ /employees –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏ ‚ïê‚ïê‚ïê
        lines.append("\n‚ïê‚ïê‚ïê –ü–û–í–ê–†–ê –í IIKO (—Å–ø—Ä–∞–≤–∫–∞) ‚ïê‚ïê‚ïê")
        try:
            text = await self._get("/resto/api/employees")
            root = ET.fromstring(text)
            cook_names = []
            for emp in root.findall(".//employee"):
                if (emp.findtext("deleted") or "false") == "true":
                    continue
                role = (emp.findtext("mainRoleCode") or "").strip()
                if cook_role_codes:
                    if role.lower() not in [c.lower() for c in cook_role_codes]:
                        continue
                else:
                    if not any(kw in role.lower() for kw in ["cook", "–ø–æ–≤–∞—Ä", "—à–µ—Ñ", "pov"]):
                        continue
                cook_names.append(emp.findtext("name") or "?")
            lines.append(f"–í—Å–µ–≥–æ –ø–æ–≤–∞—Ä–æ–≤: {len(cook_names)}")
            for n in sorted(cook_names):
                lines.append(f"  ‚Ä¢ {n}")
        except Exception as e:
            lines.append(f"–û—à–∏–±–∫–∞: {e}")

        return "\n".join(lines)

    async def get_cook_productivity_data(self, date_from: str, date_to: str) -> dict:
        """–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á—ë—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—É—Ö–Ω–∏/–ø–æ–≤–∞—Ä–æ–≤"""
        results = {}

        # 1. –ë–ª—é–¥–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–∫—É—Ö–Ω—è/–±–∞—Ä)
        try:
            results["dish_group_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup"],
                aggregate_fields=["DishAmountInt", "DishSumInt", "DishDiscountSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –ø–æ –≥—Ä—É–ø–ø–∞–º –±–ª—é–¥: {e}")

        # 3. –ë–ª—é–¥–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º + –¥–µ–Ω—å (–¥–∏–Ω–∞–º–∏–∫–∞ –∫—É—Ö–Ω–∏ –ø–æ –¥–Ω—è–º)
        try:
            results["dish_group_day_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup", "OpenDate.Typed"],
                aggregate_fields=["DishAmountInt", "DishSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≥—Ä—É–ø–ø—ã+–¥–µ–Ω—å: {e}")

        # 4. –ö—É—Ö–Ω—è –ø–æ —á–∞—Å–∞–º (–ø–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞)
        try:
            results["dish_hour_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup", "HourOpen"],
                aggregate_fields=["DishAmountInt", "DishSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≥—Ä—É–ø–ø—ã+—á–∞—Å: {e}")

        # 5. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –±–ª—é–¥–∞ (—Ç–æ–ø –ø–æ –≤—ã—Ä—É—á–∫–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É)
        try:
            results["dish_detail_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishName", "DishGroup"],
                aggregate_fields=["DishAmountInt", "DishSumInt", "DishDiscountSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –¥–µ—Ç–∞–ª–∏ –±–ª—é–¥: {e}")

        # 6. –û–±—â–∏–µ –∏—Ç–æ–≥–∏ –ø–æ –¥–Ω—è–º (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        try:
            results["day_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["OpenDate.Typed"],
                aggregate_fields=["DishAmountInt", "DishSumInt",
                                  "DishDiscountSumInt", "UniqOrderId.OrdersCount"]
            )
        except Exception as e:
            logger.warning(f"OLAP –ø–æ –¥–Ω—è–º: {e}")

        # 7. –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ –∫—É—Ö–æ–Ω–Ω—ã–º —Å—Ç–∞–Ω—Ü–∏—è–º
        try:
            results["cooking_place_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["CookingPlace"],
                aggregate_fields=["DishAmountInt", "DishSumInt",
                                  "Cooking.CookingDuration.Avg",
                                  "Cooking.KitchenTime.Avg",
                                  "Cooking.GuestWaitTime.Avg"]
            )
        except Exception as e:
            logger.warning(f"OLAP –∫—É—Ö–æ–Ω–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏: {e}")

        # 8. –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –±–ª—é–¥
        try:
            results["cooking_time_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup"],
                aggregate_fields=["DishAmountInt", "DishSumInt",
                                  "Cooking.CookingDuration.Avg",
                                  "Cooking.KitchenTime.Avg",
                                  "Cooking.ServeTime.Avg",
                                  "Cooking.CookingLateTime.Avg"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≤—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏: {e}")

        # 9. –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ —á–∞—Å–∞–º (–ø–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏ ‚Üí –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ)
        try:
            results["cooking_hour_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["HourOpen"],
                aggregate_fields=["DishAmountInt",
                                  "Cooking.CookingDuration.Avg",
                                  "Cooking.GuestWaitTime.Avg",
                                  "UniqOrderId.OrdersCount"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≤—Ä–µ–º—è+—á–∞—Å—ã: {e}")

        if not results:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ö–Ω–∏"}

        return results

    # –ì—Ä—É–ø–ø—ã, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –±–∞—Ä—É (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫—É—Ö–æ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π)
    BAR_GROUPS = {
        "–∞–ª–∫–æ–≥–æ–ª—å–Ω—ã–µ –∫–æ–∫—Ç–µ–π–ª–∏", "–±–∞—Ä", "–±–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω—ã–µ –Ω–∞–ø–∏—Ç–∫–∏",
        "–±—Ä–µ–Ω–¥–∏ –∏ –∫–æ–Ω—å—è–∫", "–≤–µ—Ä–º—É—Ç", "–≤–∏–Ω–æ", "–≤–∏–Ω–æ –±–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω–æ–µ",
        "–≤–∏–Ω–æ –±–µ–ª–æ–µ", "–≤–∏–Ω–æ –∏–≥—Ä–∏—Å—Ç–æ–µ", "–≤–∏–Ω–æ –∫—Ä–∞—Å–Ω–æ–µ", "–≤–∏–Ω–æ –æ—Ä–∞–Ω–∂–µ–≤–æ–µ",
        "–≤–∏–Ω–æ —Ä–æ–∑–æ–≤–æ–µ", "–≤–∏–Ω–æ –ø–æ –±–æ–∫–∞–ª–∞–º", "–≤–∏—Å–∫–∏", "–≤–æ–¥–∞", "–≤–æ–¥–∫–∞",
        "–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–ø–∏—Ç–∫–∏", "–¥–∂–∏–Ω", "–∫–æ—Ñ–µ", "–∫—Ä–∞—Ñ—Ç–æ–≤—ã–π —á–∞–π",
        "–∫—Ä–µ–ø–∫–∏–π –∞–ª–∫–æ–≥–æ–ª—å", "–ª–∏–∫–µ—Ä—ã –∏ –Ω–∞—Å—Ç–æ–π–∫–∏", "–ª–∏–º–æ–Ω–∞–¥—ã",
        "–º–∏–ª–∫—à–µ–π–∫–∏ –∏ —Å–ª–∞–¥–∫–∏–µ –Ω–∞–ø–∏—Ç–∫–∏", "–ø–∏–≤–æ", "–ø–∏–≤–æ –±—É—Ç—ã–ª–æ—á–Ω–æ–µ",
        "—Ä–∞–∑–ª–∏–≤–Ω–æ–µ –ø–∏–≤–æ", "—Ä–æ–º", "—Å–æ–∫", "—Ç–µ–∫–∏–ª–∞", "—á–∞–π",
        "—Å–æ–∫–∏&–º–æ—Ä—Å&gazirovka", "water",
    }

    def _is_bar_group(self, group_name: str) -> bool:
        return group_name.lower().strip() in self.BAR_GROUPS

    async def get_cook_productivity_summary(self, date_from: str, date_to: str,
                                              cooks_count: int = 0,
                                              cook_salary: float = 0) -> str:
        """–°–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—É—Ö–Ω–∏ –¥–ª—è Claude.
        cooks_count –∏ cook_salary –ø—Ä–∏—Ö–æ–¥—è—Ç –∏–∑ Google Sheets (—á–µ—Ä–µ–∑ bot.py).
        """
        data = await self.get_cook_productivity_data(date_from, date_to)

        if "error" in data:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {data['error']}"

        effective_salary = cook_salary
        effective_cooks = cooks_count

        lines = [f"üìä === –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ö–£–•–ù–ò ({date_from} ‚Äî {date_to}) ==="]

        # ‚îÄ‚îÄ‚îÄ –°–æ–±–∏—Ä–∞–µ–º –≤—ã—Ä—É—á–∫—É –∫—É—Ö–Ω–∏ –ø–æ –¥–Ω—è–º ‚îÄ‚îÄ‚îÄ
        dish_group_day_rows = data.get("dish_group_day_rows", [])
        daily_kitchen = defaultdict(float)
        for row in dish_group_day_rows:
            group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
            if self._is_bar_group(group):
                continue
            day = row.get("OpenDate.Typed") or row.get("–£—á–µ—Ç–Ω—ã–π –¥–µ–Ω—å") or "?"
            revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
            daily_kitchen[day] += revenue

        # ‚îÄ‚îÄ‚îÄ –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ‚îÄ‚îÄ‚îÄ
        if daily_kitchen and effective_cooks > 0:
            lines.append(f"\n–ü–æ–≤–∞—Ä–æ–≤ –≤ —Å–º–µ–Ω–µ: {effective_cooks} (Google Sheets)")
            if effective_salary > 0:
                lines.append(f"–°—Ä. –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ–≤–∞—Ä–∞ –∑–∞ –¥–µ–Ω—å: {effective_salary:.0f} —Ä—É–±. (Google Sheets)")

            # –ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∫–æ–ª-–≤–∞ –ø–æ–≤–∞—Ä–æ–≤
            hyp_counts = sorted(set([3, 5, 6]) - {effective_cooks})[:3]

            lines.append("")
            lines.append("=== –í–´–†–£–ß–ö–ê –ö–£–•–ù–ò –ü–û –î–ù–Ø–ú ===")
            hyp_header = " | ".join([f"–ì–∏–ø.{h}" for h in hyp_counts])
            lines.append(f"  –î–∞—Ç–∞       | –í—ã—Ä—É—á–∫–∞ –∫—É—Ö–Ω–∏ | –ü–æ–≤–∞—Ä–æ–≤ | –ù–∞ 1 –ø–æ–≤–∞—Ä–∞ | {hyp_header}")
            lines.append(f"  {'-' * 70}")

            total_rev = 0
            day_data = []
            for day in sorted(daily_kitchen.keys()):
                rev = daily_kitchen[day]
                total_rev += rev
                per_cook = rev / effective_cooks
                hyp_vals = [rev / h for h in hyp_counts]
                day_data.append({"day": day, "rev": rev, "per_cook": per_cook, "hyp": hyp_vals})

                # –ö–æ—Ä–æ—Ç–∫–∞—è –¥–∞—Ç–∞ (dd.mm)
                short_day = day[8:10] + "." + day[5:7] if len(day) >= 10 else day
                hyp_str = " | ".join([f"{v:>7.0f}" for v in hyp_vals])
                lines.append(
                    f"  {short_day:10} | {rev:>13.0f} | {effective_cooks:>7} | {per_cook:>11.0f} | {hyp_str}"
                )

            num_days = len(day_data)
            avg_per_cook = (total_rev / effective_cooks / num_days) if num_days > 0 else 0
            hyp_totals = " | ".join([f"{total_rev / h / num_days:>7.0f}" for h in hyp_counts])
            lines.append(f"  {'-' * 70}")
            lines.append(
                f"  {'–ò–¢–û–ì–û':10} | {total_rev:>13.0f} | {effective_cooks:>7} | {avg_per_cook:>11.0f} | {hyp_totals}"
            )
            lines.append(f"  –î–Ω–µ–π: {num_days}")

            # ‚îÄ‚îÄ‚îÄ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ‚îÄ‚îÄ‚îÄ
            if effective_salary > 0:
                coeff = avg_per_cook / effective_salary
                lines.append(f"\n=== –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò ===")
                lines.append(f"  –í—ã—Ä—É—á–∫–∞ –Ω–∞ 1 –ø–æ–≤–∞—Ä–∞ –≤ –¥–µ–Ω—å: {avg_per_cook:.0f} —Ä—É–±.")
                lines.append(f"  –ó–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ–≤–∞—Ä–∞ –∑–∞ –¥–µ–Ω—å:    {effective_salary:.0f} —Ä—É–±.")
                lines.append(f"  –ö–æ—ç—Ñ—Ñ. (—Ñ–∞–∫—Ç):              {coeff:.1f}")
                for h in hyp_counts:
                    hyp_per_cook = total_rev / h / num_days
                    hyp_coeff = hyp_per_cook / effective_salary
                    lines.append(f"  –ö–æ—ç—Ñ—Ñ. (–≥–∏–ø. {h} –ø–æ–≤–∞—Ä–æ–≤):   {hyp_coeff:.1f}")

                lines.append("")
                if coeff >= 3:
                    lines.append(f"  –û—Ü–µ–Ω–∫–∞: –û–¢–õ–ò–ß–ù–û ‚Äî –ø–æ–≤–∞—Ä–∞ –æ–∫—É–ø–∞—é—Ç—Å—è –≤ {coeff:.1f}x")
                elif coeff >= 2:
                    lines.append(f"  –û—Ü–µ–Ω–∫–∞: –•–û–†–û–®–û ‚Äî –ø–æ–≤–∞—Ä–∞ –æ–∫—É–ø–∞—é—Ç—Å—è –≤ {coeff:.1f}x")
                elif coeff >= 1:
                    lines.append(f"  –û—Ü–µ–Ω–∫–∞: –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û ‚Äî –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å {coeff:.1f}x")
                else:
                    lines.append(f"  –û—Ü–µ–Ω–∫–∞: –ù–ò–ó–ö–ê–Ø ‚Äî –ø–æ–≤–∞—Ä–∞ –Ω–µ –æ–∫—É–ø–∞—é—Ç –∑–∞—Ä–ø–ª–∞—Ç—É ({coeff:.1f}x)")

        elif not daily_kitchen:
            lines.append("\n‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—ã—Ä—É—á–∫–µ –∫—É—Ö–Ω–∏ –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥")
        else:
            lines.append("\n‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–æ–≤–∞—Ä–∞–º. –ü—Ä–∏–≤—è–∂–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É –∑–∞—Ä–ø–ª–∞—Ç: /setsheet <—Å—Å—ã–ª–∫–∞>")

        # ‚îÄ‚îÄ‚îÄ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–ª—é–¥ (–∫—É—Ö–Ω—è vs –±–∞—Ä) ‚îÄ‚îÄ‚îÄ
        dish_group_rows = data.get("dish_group_rows", [])
        if dish_group_rows:
            lines.append("\n=== –í–´–†–£–ß–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú ===")
            kitchen_groups = []
            kitchen_total_rev = 0
            bar_total_rev = 0
            for row in dish_group_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
                if self._is_bar_group(group):
                    bar_total_rev += revenue
                else:
                    kitchen_total_rev += revenue
                    kitchen_groups.append({"group": group, "qty": qty, "revenue": revenue})
            lines.append(f"  –ö–£–•–ù–Ø: {kitchen_total_rev:.0f} —Ä—É–±.")
            for g in sorted(kitchen_groups, key=lambda x: x["revenue"], reverse=True):
                lines.append(f"    {g['group']} | {g['qty']:.0f} —à—Ç | {g['revenue']:.0f} —Ä—É–±.")
            lines.append(f"  –ë–ê–†: {bar_total_rev:.0f} —Ä—É–±.")

        # ‚îÄ‚îÄ‚îÄ –¢–æ–ø –∫—É—Ö–æ–Ω–Ω—ã—Ö –±–ª—é–¥ ‚îÄ‚îÄ‚îÄ
        dish_detail_rows = data.get("dish_detail_rows", [])
        if dish_detail_rows:
            lines.append("\n=== –¢–û–ü –ö–£–•–û–ù–ù–´–• –ë–õ–Æ–î ===")
            kitchen_dishes = []
            for row in dish_detail_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                if self._is_bar_group(group):
                    continue
                name = row.get("DishName") or row.get("–ë–ª—é–¥–æ") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
                kitchen_dishes.append({"name": name, "qty": qty, "revenue": revenue})
            for d in sorted(kitchen_dishes, key=lambda x: x["qty"], reverse=True)[:15]:
                lines.append(f"  {d['name']} | {d['qty']:.0f} —à—Ç | {d['revenue']:.0f} —Ä—É–±.")

        return "\n".join(lines)

    async def test_connection(self) -> str:
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        try:
            await self._ensure_token()
            return f"‚úÖ iikoServer –ø–æ–¥–∫–ª—é—á—ë–Ω ({self.server_url})"
        except Exception as e:
            return f"‚ùå iikoServer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}"

    async def close(self):
        await self.client.aclose()
