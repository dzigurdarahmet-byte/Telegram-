"""
iiko Server API –∫–ª–∏–µ–Ω—Ç (–ª–æ–∫–∞–ª—å–Ω—ã–π)
–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–ª–∞ (–∑–∞–∫–∞–∑—ã —Å—Ç–æ–ª–æ–≤, OLAP, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏)

–°–¢–†–ê–¢–ï–ì–ò–Ø: –ù–µ—Å–∫–æ–ª—å–∫–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö OLAP-–∑–∞–ø—Ä–æ—Å–æ–≤ –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ.
–≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ–±—Ä–µ–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–º –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Å—Ç—Ä–æ–∫.
"""

import hashlib
import httpx
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import Optional
from collections import defaultdict
import logging
import json
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

logger = logging.getLogger(__name__)


class IikoServerClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è iikoServer API"""

    def __init__(self, server_url: str, login: str, password: str):
        self.server_url = server_url.rstrip("/")
        self.login = login
        self.password = password
        self.password_hash = hashlib.sha1(password.encode('utf-8')).hexdigest()
        self.token: Optional[str] = None
        self.token_time: Optional[datetime] = None
        self.client = httpx.AsyncClient(timeout=60.0, verify=False)

    async def _ensure_token(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω"""
        if self.token and self.token_time and (datetime.now() - self.token_time).seconds < 600:
            return
        response = await self.client.get(
            f"{self.server_url}/resto/api/auth",
            params={"login": self.login, "pass": self.password_hash}
        )
        response.raise_for_status()
        self.token = response.text.strip().strip('"')
        self.token_time = datetime.now()
        logger.info("iikoServer token –ø–æ–ª—É—á–µ–Ω")

    async def _get(self, endpoint: str, params: dict = None) -> str:
        """GET-–∑–∞–ø—Ä–æ—Å"""
        await self._ensure_token()
        if params is None:
            params = {}
        params["key"] = self.token
        response = await self.client.get(
            f"{self.server_url}{endpoint}", params=params
        )
        response.raise_for_status()
        return response.text

    # ‚îÄ‚îÄ‚îÄ OLAP-–∑–∞–ø—Ä–æ—Å—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def _olap_request(self, date_from: str, date_to: str,
                            group_fields: list, aggregate_fields: list) -> list:
        """
        –û–¥–∏–Ω OLAP-–∑–∞–ø—Ä–æ—Å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (dict).
        """
        await self._ensure_token()

        json_body = {
            "reportType": "SALES",
            "buildSummary": "false",
            "groupByRowFields": group_fields,
            "groupByColFields": [],
            "aggregateFields": aggregate_fields,
            "filters": {
                "OpenDate.Typed": {
                    "filterType": "DateRange",
                    "periodType": "CUSTOM",
                    "from": date_from,
                    "to": date_to,
                    "includeLow": "true",
                    "includeHigh": "true"
                }
            }
        }

        response = await self.client.post(
            f"{self.server_url}/resto/api/v2/reports/olap",
            params={"key": self.token},
            json=json_body
        )
        logger.info(f"OLAP [{','.join(group_fields)}]: status={response.status_code}, len={len(response.text)}")
        response.raise_for_status()

        return self._parse_olap_response(response.text)

    def _parse_olap_response(self, text: str) -> list:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å OLAP-–æ—Ç–≤–µ—Ç –≤ —Å–ø–∏—Å–æ–∫ dict"""
        text = text.strip()
        if not text:
            return []

        # JSON
        if text.startswith("{") or text.startswith("["):
            try:
                data = json.loads(text)
                if isinstance(data, list):
                    return data
                if isinstance(data, dict):
                    for key in ["data", "rows", "records", "items", "result"]:
                        if key in data and isinstance(data[key], list):
                            return data[key]
                    return [data] if data else []
            except json.JSONDecodeError:
                pass

        # XML
        if text.startswith("<"):
            return self._parse_xml_rows(text)

        # CSV/TSV
        if "\t" in text:
            return self._parse_tsv_rows(text)

        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç OLAP: {text[:200]}")
        return []

    def _parse_xml_rows(self, xml_text: str) -> list:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å XML"""
        try:
            root = ET.fromstring(xml_text)
        except ET.ParseError:
            return []
        rows = []
        for tag in [".//row", ".//record", ".//item", ".//r"]:
            found = root.findall(tag)
            if found:
                for row in found:
                    row_data = {}
                    for child in row:
                        row_data[child.tag] = child.text
                    if row.attrib:
                        row_data.update(row.attrib)
                    if row_data:
                        rows.append(row_data)
                break
        if not rows:
            for elem in root.iter():
                if elem.attrib and elem.tag not in ['olap', 'report', 'result', 'response']:
                    rows.append(dict(elem.attrib))
        return rows

    def _parse_tsv_rows(self, text: str) -> list:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å TSV"""
        lines = text.strip().split("\n")
        if len(lines) < 2:
            return []
        headers = lines[0].split("\t")
        rows = []
        for line in lines[1:]:
            if line.strip():
                values = line.split("\t")
                row = dict(zip(headers, values))
                rows.append(row)
        return rows

    # ‚îÄ‚îÄ‚îÄ –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_olap_report(self, date_from: str, date_to: str,
                              report_type: str = "SALES") -> str:
        """
        –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç raw —Ç–µ–∫—Å—Ç.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥.
        """
        await self._ensure_token()
        json_body = {
            "reportType": report_type,
            "buildSummary": "false",
            "groupByRowFields": ["OpenDate.Typed"],
            "groupByColFields": [],
            "aggregateFields": [
                "DishDiscountSumInt", "DishAmountInt",
                "DishSumInt", "UniqOrderId.OrdersCount"
            ],
            "filters": {
                "OpenDate.Typed": {
                    "filterType": "DateRange",
                    "periodType": "CUSTOM",
                    "from": date_from,
                    "to": date_to,
                    "includeLow": "true",
                    "includeHigh": "true"
                }
            }
        }
        response = await self.client.post(
            f"{self.server_url}/resto/api/v2/reports/olap",
            params={"key": self.token},
            json=json_body
        )
        response.raise_for_status()
        return response.text

    async def get_sales_data(self, date_from: str, date_to: str) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö ‚Äî –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            # –ó–∞–ø—Ä–æ—Å 1: –ø–æ –¥–Ω—è–º (‚âà25 —Å—Ç—Ä–æ–∫) ‚Äî –æ—Å–Ω–æ–≤–Ω—ã–µ –∏—Ç–æ–≥–∏
            day_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["OpenDate.Typed"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"–ü–æ –¥–Ω—è–º: {len(day_rows)} —Å—Ç—Ä–æ–∫")

            # –ó–∞–ø—Ä–æ—Å 2: –ø–æ –æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∞–º (‚âà10-20 —Å—Ç—Ä–æ–∫)
            waiter_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["OrderWaiter.Name"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"–ü–æ –æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∞–º: {len(waiter_rows)} —Å—Ç—Ä–æ–∫")

            # –ó–∞–ø—Ä–æ—Å 3: –ø–æ —á–∞—Å–∞–º (‚âà15-20 —Å—Ç—Ä–æ–∫)
            hour_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["HourOpen"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt", "UniqOrderId.OrdersCount"]
            )
            logger.info(f"–ü–æ —á–∞—Å–∞–º: {len(hour_rows)} —Å—Ç—Ä–æ–∫")

            # –ó–∞–ø—Ä–æ—Å 4: –ø–æ –±–ª—é–¥–∞–º (‚âà100-200 —Å—Ç—Ä–æ–∫)
            dish_rows = await self._olap_request(
                date_from, date_to,
                group_fields=["DishName", "DishGroup"],
                aggregate_fields=["DishDiscountSumInt", "DishSumInt",
                                  "DishAmountInt"]
            )
            logger.info(f"–ü–æ –±–ª—é–¥–∞–º: {len(dish_rows)} —Å—Ç—Ä–æ–∫")

            return {
                "day_rows": day_rows,
                "waiter_rows": waiter_rows,
                "hour_rows": hour_rows,
                "dish_rows": dish_rows,
                "multi_query": True
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ OLAP: {e}")
            return {"error": str(e)}

    # ‚îÄ‚îÄ‚îÄ –°–≤–æ–¥–∫–∞ –¥–ª—è Claude ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_sales_summary(self, date_from: str, date_to: str) -> str:
        """–°–≤–æ–¥–∫–∞ –ø—Ä–æ–¥–∞–∂ –∑–∞–ª–∞ ‚Äî —Ç–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        data = await self.get_sales_data(date_from, date_to)

        if "error" in data:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–ª–∞: {data['error']}"

        lines = ["üìä === –î–ê–ù–ù–´–ï –ó–ê–õ–ê (iikoServer) ==="]

        # ‚îÄ‚îÄ‚îÄ –ò—Ç–æ–≥–∏ –ø–æ –¥–Ω—è–º ‚îÄ‚îÄ‚îÄ
        day_rows = data.get("day_rows", [])
        total_revenue = 0
        total_revenue_full = 0
        total_qty = 0
        total_orders = 0

        day_stats = {}
        for row in day_rows:
            date = row.get("OpenDate.Typed") or row.get("–£—á–µ—Ç–Ω—ã–π –¥–µ–Ω—å") or ""
            revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
            revenue_full = float(row.get("DishSumInt") or row.get("–°—É–º–º–∞ –±–µ–∑ —Å–∫–∏–¥–∫–∏") or 0)
            qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
            orders = float(row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0)

            total_revenue += revenue
            total_revenue_full += revenue_full
            total_qty += qty
            total_orders += orders

            if date:
                day_stats[date] = {
                    "revenue": revenue, "revenue_full": revenue_full,
                    "qty": qty, "orders": orders
                }

        lines.append(f"–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞ –∑–∞–ª–∞ (—Å–æ —Å–∫–∏–¥–∫–æ–π): {total_revenue:.0f} —Ä—É–±.")
        lines.append(f"–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞ –∑–∞–ª–∞ (–±–µ–∑ —Å–∫–∏–¥–∫–∏): {total_revenue_full:.0f} —Ä—É–±.")
        lines.append(f"–í—Å–µ–≥–æ –∑–∞–∫–∞–∑–æ–≤: {total_orders:.0f}")
        lines.append(f"–í—Å–µ–≥–æ –ø—Ä–æ–¥–∞–Ω–æ: {total_qty:.0f} —à—Ç")
        if total_orders > 0:
            lines.append(f"–°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {total_revenue / total_orders:.0f} —Ä—É–±.")
        lines.append(f"–°—Ç—Ä–æ–∫ –ø–æ –¥–Ω—è–º: {len(day_rows)}")
        lines.append("")

        # ‚îÄ‚îÄ‚îÄ –ü–æ –¥–Ω—è–º ‚îÄ‚îÄ‚îÄ
        if day_stats:
            lines.append("–ü–æ –¥–Ω—è–º:")
            for day, stats in sorted(day_stats.items()):
                lines.append(f"  {day} | {stats['revenue']:.0f} —Ä—É–±. | {stats['orders']:.0f} –∑–∞–∫–∞–∑–æ–≤")

        # ‚îÄ‚îÄ‚îÄ –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏ ‚îÄ‚îÄ‚îÄ
        waiter_rows = data.get("waiter_rows", [])
        if waiter_rows:
            lines.append("")
            lines.append("–°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏:")
            waiter_list = []
            for row in waiter_rows:
                name = row.get("OrderWaiter.Name") or row.get("–û—Ñ–∏—Ü–∏–∞–Ω—Ç –∑–∞–∫–∞–∑–∞") or "?"
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                orders = float(row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0)
                waiter_list.append({"name": name, "revenue": revenue, "orders": orders})

            for w in sorted(waiter_list, key=lambda x: x["revenue"], reverse=True):
                avg_check = w["revenue"] / w["orders"] if w["orders"] > 0 else 0
                lines.append(f"  {w['name']} | {w['revenue']:.0f} —Ä—É–±. | {w['orders']:.0f} –∑–∞–∫–∞–∑–æ–≤ | —Å—Ä.—á–µ–∫ {avg_check:.0f}")

        # ‚îÄ‚îÄ‚îÄ –ü–æ —á–∞—Å–∞–º ‚îÄ‚îÄ‚îÄ
        hour_rows = data.get("hour_rows", [])
        if hour_rows:
            lines.append("")
            lines.append("–ü–æ —á–∞—Å–∞–º:")
            hour_list = []
            for row in hour_rows:
                hour = row.get("HourOpen") or row.get("–ß–∞—Å –æ—Ç–∫—Ä—ã—Ç–∏—è") or ""
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                hour_list.append({"hour": hour, "revenue": revenue})

            for h in sorted(hour_list, key=lambda x: x["hour"]):
                lines.append(f"  {h['hour']}:00 | {h['revenue']:.0f} —Ä—É–±.")

        # ‚îÄ‚îÄ‚îÄ –¢–æ–ø –±–ª—é–¥ ‚îÄ‚îÄ‚îÄ
        dish_rows = data.get("dish_rows", [])
        if dish_rows:
            lines.append("")
            lines.append(f"–ü—Ä–æ–¥–∞–∂–∏ –ø–æ –±–ª—é–¥–∞–º (–≤—Å–µ–≥–æ {len(dish_rows)} –ø–æ–∑–∏—Ü–∏–π):")
            dish_list = []
            for row in dish_rows:
                name = row.get("DishName") or row.get("–ë–ª—é–¥–æ") or "?"
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                dish_list.append({"name": name, "group": group, "revenue": revenue, "qty": qty})

            for d in sorted(dish_list, key=lambda x: x["revenue"], reverse=True)[:30]:
                lines.append(f"  {d['name']} | {d['qty']:.0f} —à—Ç | {d['revenue']:.0f} —Ä—É–±. | {d['group']}")

        return "\n".join(lines)

    async def get_products(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø—Ä–æ–¥—É–∫—Ç—ã —Å —Å–µ—Ä–≤–µ—Ä–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç {id: name, sku: name}"""
        result = {}
        try:
            text = await self._get("/resto/api/v2/entities/products/list")
            data = json.loads(text) if text.strip().startswith("[") or text.strip().startswith("{") else []
            if isinstance(data, dict):
                data = data.get("data") or data.get("items") or data.get("products") or []
            for p in data:
                name = p.get("name") or p.get("title") or ""
                if not name:
                    continue
                if p.get("id"):
                    result[p["id"]] = name
                for key in ["code", "sku", "num", "article"]:
                    val = p.get(key)
                    if val:
                        result[val] = name
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–¥—É–∫—Ç—ã —Å —Å–µ—Ä–≤–µ—Ä–∞: {e}")
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
            try:
                text = await self._get("/resto/api/products")
                if text.strip().startswith("<"):
                    root = ET.fromstring(text)
                    for p in root.findall(".//*"):
                        name = p.findtext("name") or p.get("name", "")
                        pid = p.findtext("id") or p.get("id", "")
                        code = p.findtext("code") or p.get("code", "")
                        if name and pid:
                            result[pid] = name
                        if name and code:
                            result[code] = name
                elif text.strip().startswith("["):
                    for p in json.loads(text):
                        name = p.get("name", "")
                        if name:
                            if p.get("id"):
                                result[p["id"]] = name
                            if p.get("code"):
                                result[p["code"]] = name
            except Exception as e2:
                logger.warning(f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
        return result

    async def get_product_groups(self) -> list:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å —Å–µ—Ä–≤–µ—Ä–∞"""
        try:
            text = await self._get("/resto/api/v2/entities/products/group/list")
            data = json.loads(text) if text.strip() else []
            if isinstance(data, dict):
                data = data.get("data") or data.get("items") or data.get("groups") or []
            groups = []
            for g in data:
                name = g.get("name") or g.get("title") or ""
                gid = g.get("id", "")
                parent = g.get("parentId") or g.get("parent", "")
                if name:
                    groups.append({"id": gid, "name": name, "parent": parent})
            return groups
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≥—Ä—É–ø–ø—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {e}")
            return []

    async def get_employees(self) -> list:
        """–°–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        try:
            text = await self._get("/resto/api/employees")
            if text.strip().startswith("["):
                return json.loads(text)
            root = ET.fromstring(text)
            employees = []
            for emp in root.findall(".//employee"):
                name = emp.findtext("name") or ""
                if name:
                    employees.append({"name": name, "id": emp.findtext("id") or ""})
            return employees
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")
            return []

    async def get_roles_debug(self) -> str:
        """–û—Ç–ª–∞–¥–∫–∞: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–æ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        lines = []

        # –í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —Ä–æ–ª–∏ –ø—Ä—è–º–æ –∏–∑ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        try:
            text = await self._get("/resto/api/employees")
            root = ET.fromstring(text)
            role_employees = {}
            for emp in root.findall(".//employee"):
                deleted = emp.findtext("deleted") or "false"
                if deleted == "true":
                    continue
                name = emp.findtext("name") or "?"
                code = emp.findtext("mainRoleCode") or "?"
                if code not in role_employees:
                    role_employees[code] = []
                role_employees[code].append(name)

            lines.append(f"–î–æ–ª–∂–Ω–æ—Å—Ç–∏ (–∏–∑ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤):")
            for code, names in sorted(role_employees.items()):
                lines.append(f"\n  [{code}] ‚Äî {len(names)} —á–µ–ª:")
                for n in names[:10]:
                    lines.append(f"    ‚Ä¢ {n}")
                if len(names) > 10:
                    lines.append(f"    ... –µ—â—ë {len(names) - 10}")
        except Exception as e:
            lines.append(f"–û—à–∏–±–∫–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")

        # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —Ä–æ–ª–µ–π
        role_endpoints = [
            "/resto/api/corporation/roles",
            "/resto/api/roles",
        ]
        for ep in role_endpoints:
            try:
                text = await self._get(ep)
                lines.append(f"\n{ep}: {text[:500]}")
            except Exception:
                pass

        return "\n".join(lines)

    async def get_employees_debug(self) -> str:
        """–û—Ç–ª–∞–¥–∫–∞: –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        try:
            text = await self._get("/resto/api/employees")
            # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã—Ö 2 –∑–∞–ø–∏—Å–∏
            if text.strip().startswith("["):
                data = json.loads(text)
                sample = data[:2] if len(data) > 2 else data
                return f"JSON ({len(data)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤):\n" + json.dumps(sample, ensure_ascii=False, indent=2, default=str)[:3800]
            elif text.strip().startswith("<"):
                return f"XML (–ø–µ—Ä–≤—ã–µ 3000 —Å–∏–º–≤–æ–ª–æ–≤):\n{text[:3000]}"
            return text[:3000]
        except Exception as e:
            return f"–û—à–∏–±–∫–∞: {e}"

    # ‚îÄ‚îÄ‚îÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–≤–∞—Ä–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    async def get_cook_staff_data(self, cook_role_codes: list = None) -> dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–≤–∞—Ä–æ–≤ –∏ –∏—Ö –∑–∞—Ä–ø–ª–∞—Ç—ã –∏–∑ iiko.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"cooks": [...], "avg_salary": float, "count": int}
        """
        result = {"cooks": [], "avg_salary": 0, "count": 0, "source": ""}

        try:
            text = await self._get("/resto/api/employees")
            root = ET.fromstring(text)

            # –í—Å–µ –ø–æ–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ ‚Äî –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            all_fields = set()
            for emp in root.findall(".//employee"):
                for child in emp:
                    all_fields.add(child.tag)
            result["available_fields"] = sorted(all_fields)

            # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–≤–∞—Ä–æ–≤
            for emp in root.findall(".//employee"):
                deleted = emp.findtext("deleted") or "false"
                if deleted == "true":
                    continue

                role_code = (emp.findtext("mainRoleCode") or "").strip()
                name = emp.findtext("name") or "?"

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø–æ–≤–∞—Ä –ª–∏ —ç—Ç–æ
                is_cook = False
                if cook_role_codes:
                    is_cook = role_code.lower() in [c.lower() for c in cook_role_codes]
                else:
                    # –ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç –ø–æ —Ç–∏–ø–∏—á–Ω—ã–º –∫–æ–¥–∞–º/–Ω–∞–∑–≤–∞–Ω–∏—è–º
                    role_lower = role_code.lower()
                    cook_keywords = ["cook", "–ø–æ–≤–∞—Ä", "—à–µ—Ñ", "chef", "–∫—É—Ö–Ω", "kitchen"]
                    is_cook = any(kw in role_lower for kw in cook_keywords)

                if not is_cook:
                    continue

                # –ò—â–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É –≤–æ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–ª—è—Ö
                salary = 0
                salary_field = ""
                salary_fields = [
                    "wage", "salary", "shiftSalary", "ratePerShift",
                    "ratePerHour", "baseSalary", "payRate",
                    "mainRateValue", "rateValue", "rate",
                ]
                for field in salary_fields:
                    val = emp.findtext(field)
                    if val:
                        try:
                            salary = float(val)
                            salary_field = field
                            break
                        except (ValueError, TypeError):
                            pass

                result["cooks"].append({
                    "name": name,
                    "role": role_code,
                    "salary": salary,
                    "salary_field": salary_field,
                })

            # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –∑–∞—Ä–ø–ª–∞—Ç—É
            cooks_with_salary = [c for c in result["cooks"] if c["salary"] > 0]
            result["count"] = len(result["cooks"])
            if cooks_with_salary:
                result["avg_salary"] = sum(c["salary"] for c in cooks_with_salary) / len(cooks_with_salary)
                result["source"] = f"iiko (–ø–æ–ª–µ: {cooks_with_salary[0]['salary_field']})"
            else:
                result["source"] = "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ iiko"

        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–≤–∞—Ä–æ–≤: {e}")
            result["error"] = str(e)

        return result

    def _xml_to_text(self, elem, indent=0) -> list:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ—á—å –≤—Å–µ –ø–æ–ª—è –∏–∑ XML-—ç–ª–µ–º–µ–Ω—Ç–∞"""
        lines = []
        prefix = "  " * indent
        for child in elem:
            text = (child.text or "").strip()
            has_children = len(list(child)) > 0
            if has_children:
                lines.append(f"{prefix}{child.tag}:")
                lines.extend(self._xml_to_text(child, indent + 1))
            elif text and len(text) < 300:
                lines.append(f"{prefix}{child.tag}: {text}")
        return lines

    async def get_cook_salary_debug(self, cook_role_codes: list = None) -> str:
        """–û—Ç–ª–∞–¥–∫–∞: –≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫ —Å—Ç–∞–≤–æ–∫ –∏ —á–∞—Å–æ–≤ –ø–æ–≤–∞—Ä–æ–≤ –≤ iiko"""
        lines = []

        # ‚ïê‚ïê‚ïê 1. –ü–æ–ª–Ω—ã–π XML –ø–æ–≤–∞—Ä–æ–≤ (—Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏) ‚ïê‚ïê‚ïê
        try:
            text = await self._get("/resto/api/employees")
            root = ET.fromstring(text)

            cook_count = 0
            cook_ids = []
            for emp in root.findall(".//employee"):
                deleted = emp.findtext("deleted") or "false"
                if deleted == "true":
                    continue
                role_code = (emp.findtext("mainRoleCode") or "").strip()
                is_cook = role_code.lower() in [c.lower() for c in (cook_role_codes or [])]
                if not cook_role_codes:
                    is_cook = any(kw in role_code.lower() for kw in ["cook", "–ø–æ–≤–∞—Ä", "—à–µ—Ñ", "pov"])
                if not is_cook:
                    continue
                cook_count += 1
                cook_ids.append(emp.findtext("id") or "")
                if cook_count <= 2:
                    name = emp.findtext("name") or "?"
                    lines.append(f"‚ïê‚ïê‚ïê –ü–æ–≤–∞—Ä #{cook_count}: {name} ({role_code}) ‚ïê‚ïê‚ïê")
                    lines.extend(self._xml_to_text(emp, indent=1))
                    lines.append("")

            lines.append(f"–í—Å–µ–≥–æ –ø–æ–≤–∞—Ä–æ–≤ (—Ä–æ–ª—å POV): {cook_count}")
        except Exception as e:
            lines.append(f"–û—à–∏–±–∫–∞ employees: {e}")
            cook_ids = []

        # ‚ïê‚ïê‚ïê 2. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –∑–∞—Ä–ø–ª–∞—Ç/—Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è ‚ïê‚ïê‚ïê
        wage_endpoints = [
            "/resto/api/v2/schedule/events",
            "/resto/api/v2/employees/wages",
            "/resto/api/employees/payroll",
            "/resto/api/corporation/employees",
            "/resto/api/v2/schedule/resultingSchedule",
        ]
        lines.append("\n‚ïê‚ïê‚ïê –ü–û–ò–°–ö –≠–ù–î–ü–û–ò–ù–¢–û–í –ó–ê–†–ü–õ–ê–¢ ‚ïê‚ïê‚ïê")
        for ep in wage_endpoints:
            try:
                text = await self._get(ep)
                preview = text[:300].replace("\n", " ")
                lines.append(f"‚úÖ {ep}: {preview}")
            except Exception as e:
                err = str(e)[:80]
                lines.append(f"‚ùå {ep}: {err}")

        # ‚ïê‚ïê‚ïê 3. –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–≤–∞—Ä–∞ ‚ïê‚ïê‚ïê
        if cook_ids:
            emp_id = cook_ids[0]
            per_employee_eps = [
                f"/resto/api/employees/{emp_id}",
                f"/resto/api/v2/employees/{emp_id}",
                f"/resto/api/v2/employees/{emp_id}/wages",
                f"/resto/api/v2/employees/{emp_id}/schedule",
            ]
            lines.append(f"\n‚ïê‚ïê‚ïê –î–ê–ù–ù–´–ï –ü–û–í–ê–†–ê {emp_id[:8]}... ‚ïê‚ïê‚ïê")
            for ep in per_employee_eps:
                try:
                    text = await self._get(ep)
                    preview = text[:400].replace("\n", " ")
                    lines.append(f"‚úÖ {ep}:\n  {preview}")
                except Exception as e:
                    err = str(e)[:80]
                    lines.append(f"‚ùå {ep}: {err}")

        # ‚ïê‚ïê‚ïê 4. –ü–æ–∏—Å–∫ –∑–∞—Ä–ø–ª–∞—Ç–Ω–æ–≥–æ OLAP-–æ—Ç—á—ë—Ç–∞ ‚ïê‚ïê‚ïê
        lines.append("\n‚ïê‚ïê‚ïê –ü–û–ò–°–ö –ó–ê–†–ü–õ–ê–¢–ù–û–ì–û OLAP ‚ïê‚ïê‚ïê")
        yesterday = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
        today = datetime.now().strftime("%Y-%m-%d")

        await self._ensure_token()

        # 4a. –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—Ç—á—ë—Ç–æ–≤
        report_types_to_try = [
            "SALES", "TRANSACTIONS", "EMPLOYEE_ATTENDANCES",
            "STAFF", "PAYROLL", "SCHEDULE", "WAGES",
            "CONSOLIDATED_WAGES", "SALARY",
        ]
        for rt in report_types_to_try:
            try:
                response = await self.client.get(
                    f"{self.server_url}/resto/api/v2/reports/olap/columns",
                    params={"key": self.token, "reportType": rt}
                )
                if response.status_code == 200:
                    data = json.loads(response.text)
                    field_names = sorted(data.keys()) if isinstance(data, dict) else []
                    # –ò—â–µ–º –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –ø–æ–ª—è
                    wage_kw = ["wage", "salary", "rate", "pay", "earning",
                               "—Å—Ç–∞–≤–∫", "–∑–∞—Ä–ø–ª", "–æ–∫–ª–∞–¥", "–Ω–∞—á–∏—Å–ª", "–æ–ø–ª–∞—Ç"]
                    wage_fields = [f for f in field_names
                                   if any(kw in f.lower() for kw in wage_kw)]
                    if wage_fields:
                        lines.append(f"‚úÖ {rt}: {len(field_names)} –ø–æ–ª–µ–π, –ó–ê–†–ü–õ–ê–¢–ù–´–ï: {', '.join(wage_fields)}")
                    else:
                        lines.append(f"‚úÖ {rt}: {len(field_names)} –ø–æ–ª–µ–π (–∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö –Ω–µ—Ç)")
                else:
                    lines.append(f"‚ùå {rt}: {response.status_code}")
            except Exception as e:
                lines.append(f"‚ùå {rt}: {str(e)[:60]}")

        # 4b. –ü—Ä–æ–±—É–µ–º OLAP-–∑–∞–ø—Ä–æ—Å —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –¥–ª—è –∑–∞—Ä–ø–ª–∞—Ç–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤
        lines.append("\n‚ïê‚ïê‚ïê OLAP –ó–ê–ü–†–û–°–´ (—Ä–∞–∑–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã) ‚ïê‚ïê‚ïê")
        filter_variants = [
            {"name": "–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞", "filters": {}},
            {"name": "Session.Date", "filters": {
                "Session.Date": {
                    "filterType": "DateRange", "periodType": "CUSTOM",
                    "from": yesterday, "to": today,
                    "includeLow": "true", "includeHigh": "true"
                }
            }},
            {"name": "Date", "filters": {
                "Date": {
                    "filterType": "DateRange", "periodType": "CUSTOM",
                    "from": yesterday, "to": today,
                    "includeLow": "true", "includeHigh": "true"
                }
            }},
        ]
        for rt in ["EMPLOYEE_ATTENDANCES", "CONSOLIDATED_WAGES", "SALARY", "PAYROLL"]:
            for fv in filter_variants:
                try:
                    json_body = {
                        "reportType": rt,
                        "buildSummary": "false",
                        "groupByRowFields": [],
                        "groupByColFields": [],
                        "aggregateFields": [],
                        "filters": fv["filters"]
                    }
                    response = await self.client.post(
                        f"{self.server_url}/resto/api/v2/reports/olap",
                        params={"key": self.token},
                        json=json_body
                    )
                    if response.status_code == 200:
                        preview = response.text[:300].replace("\n", " ")
                        lines.append(f"‚úÖ {rt} ({fv['name']}): {preview}")
                    else:
                        lines.append(f"‚ùå {rt} ({fv['name']}): {response.status_code}")
                except Exception as e:
                    lines.append(f"‚ùå {rt} ({fv['name']}): {str(e)[:60]}")

        # –ü—É—Å—Ç–æ ‚Äî –∑–∞–≥–ª—É—à–∫–∞
        extra_endpoints = []
        for ep in extra_endpoints:
            try:
                text = await self._get(ep)
                preview = text[:400].replace("\n", " ")
                lines.append(f"‚úÖ {ep}: {preview}")
            except Exception as e:
                err = str(e)[:80]
                lines.append(f"‚ùå {ep}: {err}")

        return "\n".join(lines)

    async def get_cook_productivity_data(self, date_from: str, date_to: str) -> dict:
        """–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—á—ë—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—É—Ö–Ω–∏/–ø–æ–≤–∞—Ä–æ–≤"""
        results = {}

        # 1. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –ø–æ–≤–∞—Ä—É (–µ—Å–ª–∏ iiko –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç)
        for field in ["Cooking.Name"]:
            try:
                cook_rows = await self._olap_request(
                    date_from, date_to,
                    group_fields=[field],
                    aggregate_fields=["DishAmountInt", "DishSumInt", "DishDiscountSumInt"]
                )
                if cook_rows:
                    results["cook_rows"] = cook_rows
                    results["cook_field"] = field
                    logger.info(f"–ü–æ–≤–∞—Ä–∞ –Ω–∞–π–¥–µ–Ω—ã —á–µ—Ä–µ–∑ {field}: {len(cook_rows)} —Å—Ç—Ä–æ–∫")
                    # –ü–æ –ø–æ–≤–∞—Ä—É + –≥—Ä—É–ø–ø–∞ –±–ª—é–¥
                    try:
                        results["cook_dish_rows"] = await self._olap_request(
                            date_from, date_to,
                            group_fields=[field, "DishGroup"],
                            aggregate_fields=["DishAmountInt", "DishSumInt"]
                        )
                    except Exception:
                        pass
                    # –ü–æ –ø–æ–≤–∞—Ä—É + –¥–µ–Ω—å
                    try:
                        results["cook_day_rows"] = await self._olap_request(
                            date_from, date_to,
                            group_fields=[field, "OpenDate.Typed"],
                            aggregate_fields=["DishAmountInt", "DishSumInt"]
                        )
                    except Exception:
                        pass
                    break
            except Exception as e:
                logger.info(f"OLAP –ø–æ–ª–µ {field} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {e}")

        # 2. –ë–ª—é–¥–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫—É—Ö–Ω—è/–±–∞—Ä)
        try:
            results["dish_group_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup"],
                aggregate_fields=["DishAmountInt", "DishSumInt", "DishDiscountSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –ø–æ –≥—Ä—É–ø–ø–∞–º –±–ª—é–¥: {e}")

        # 3. –ë–ª—é–¥–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º + –¥–µ–Ω—å (–¥–∏–Ω–∞–º–∏–∫–∞ –∫—É—Ö–Ω–∏ –ø–æ –¥–Ω—è–º)
        try:
            results["dish_group_day_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup", "OpenDate.Typed"],
                aggregate_fields=["DishAmountInt", "DishSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≥—Ä—É–ø–ø—ã+–¥–µ–Ω—å: {e}")

        # 4. –ö—É—Ö–Ω—è –ø–æ —á–∞—Å–∞–º (–ø–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞)
        try:
            results["dish_hour_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup", "HourOpen"],
                aggregate_fields=["DishAmountInt", "DishSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≥—Ä—É–ø–ø—ã+—á–∞—Å: {e}")

        # 5. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –±–ª—é–¥–∞ (—Ç–æ–ø –ø–æ –≤—ã—Ä—É—á–∫–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É)
        try:
            results["dish_detail_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishName", "DishGroup"],
                aggregate_fields=["DishAmountInt", "DishSumInt", "DishDiscountSumInt"]
            )
        except Exception as e:
            logger.warning(f"OLAP –¥–µ—Ç–∞–ª–∏ –±–ª—é–¥: {e}")

        # 6. –û–±—â–∏–µ –∏—Ç–æ–≥–∏ –ø–æ –¥–Ω—è–º (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        try:
            results["day_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["OpenDate.Typed"],
                aggregate_fields=["DishAmountInt", "DishSumInt",
                                  "DishDiscountSumInt", "UniqOrderId.OrdersCount"]
            )
        except Exception as e:
            logger.warning(f"OLAP –ø–æ –¥–Ω—è–º: {e}")

        # 7. –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ –∫—É—Ö–æ–Ω–Ω—ã–º —Å—Ç–∞–Ω—Ü–∏—è–º
        try:
            results["cooking_place_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["CookingPlace"],
                aggregate_fields=["DishAmountInt", "DishSumInt",
                                  "Cooking.CookingDuration.Avg",
                                  "Cooking.KitchenTime.Avg",
                                  "Cooking.GuestWaitTime.Avg"]
            )
        except Exception as e:
            logger.warning(f"OLAP –∫—É—Ö–æ–Ω–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏: {e}")

        # 8. –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –±–ª—é–¥
        try:
            results["cooking_time_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["DishGroup"],
                aggregate_fields=["DishAmountInt", "DishSumInt",
                                  "Cooking.CookingDuration.Avg",
                                  "Cooking.KitchenTime.Avg",
                                  "Cooking.ServeTime.Avg",
                                  "Cooking.CookingLateTime.Avg"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≤—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏: {e}")

        # 9. –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ —á–∞—Å–∞–º (–ø–∏–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏ ‚Üí –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ)
        try:
            results["cooking_hour_rows"] = await self._olap_request(
                date_from, date_to,
                group_fields=["HourOpen"],
                aggregate_fields=["DishAmountInt",
                                  "Cooking.CookingDuration.Avg",
                                  "Cooking.GuestWaitTime.Avg",
                                  "UniqOrderId.OrdersCount"]
            )
        except Exception as e:
            logger.warning(f"OLAP –≤—Ä–µ–º—è+—á–∞—Å—ã: {e}")

        if not results:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ö–Ω–∏"}

        return results

    # –ì—Ä—É–ø–ø—ã, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –±–∞—Ä—É (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫—É—Ö–æ–Ω–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π)
    BAR_GROUPS = {
        "–∞–ª–∫–æ–≥–æ–ª—å–Ω—ã–µ –∫–æ–∫—Ç–µ–π–ª–∏", "–±–∞—Ä", "–±–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω—ã–µ –Ω–∞–ø–∏—Ç–∫–∏",
        "–±—Ä–µ–Ω–¥–∏ –∏ –∫–æ–Ω—å—è–∫", "–≤–µ—Ä–º—É—Ç", "–≤–∏–Ω–æ", "–≤–∏–Ω–æ –±–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω–æ–µ",
        "–≤–∏–Ω–æ –±–µ–ª–æ–µ", "–≤–∏–Ω–æ –∏–≥—Ä–∏—Å—Ç–æ–µ", "–≤–∏–Ω–æ –∫—Ä–∞—Å–Ω–æ–µ", "–≤–∏–Ω–æ –æ—Ä–∞–Ω–∂–µ–≤–æ–µ",
        "–≤–∏–Ω–æ —Ä–æ–∑–æ–≤–æ–µ", "–≤–∏–Ω–æ –ø–æ –±–æ–∫–∞–ª–∞–º", "–≤–∏—Å–∫–∏", "–≤–æ–¥–∞", "–≤–æ–¥–∫–∞",
        "–≥–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞–ø–∏—Ç–∫–∏", "–¥–∂–∏–Ω", "–∫–æ—Ñ–µ", "–∫—Ä–∞—Ñ—Ç–æ–≤—ã–π —á–∞–π",
        "–∫—Ä–µ–ø–∫–∏–π –∞–ª–∫–æ–≥–æ–ª—å", "–ª–∏–∫–µ—Ä—ã –∏ –Ω–∞—Å—Ç–æ–π–∫–∏", "–ª–∏–º–æ–Ω–∞–¥—ã",
        "–º–∏–ª–∫—à–µ–π–∫–∏ –∏ —Å–ª–∞–¥–∫–∏–µ –Ω–∞–ø–∏—Ç–∫–∏", "–ø–∏–≤–æ", "–ø–∏–≤–æ –±—É—Ç—ã–ª–æ—á–Ω–æ–µ",
        "—Ä–∞–∑–ª–∏–≤–Ω–æ–µ –ø–∏–≤–æ", "—Ä–æ–º", "—Å–æ–∫", "—Ç–µ–∫–∏–ª–∞", "—á–∞–π",
        "—Å–æ–∫–∏&–º–æ—Ä—Å&gazirovka", "water",
    }

    def _is_bar_group(self, group_name: str) -> bool:
        return group_name.lower().strip() in self.BAR_GROUPS

    async def get_cook_productivity_summary(self, date_from: str, date_to: str,
                                              cooks_per_shift: int = 0,
                                              cook_salary: float = 0,
                                              cook_role_codes: list = None) -> str:
        """–°–≤–æ–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫—É—Ö–Ω–∏/–ø–æ–≤–∞—Ä–æ–≤ –¥–ª—è Claude"""
        data = await self.get_cook_productivity_data(date_from, date_to)

        if "error" in data:
            return f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {data['error']}"

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–≤–∞—Ä–æ–≤ –∏–∑ iiko (–∑–∞—Ä–ø–ª–∞—Ç–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
        staff = await self.get_cook_staff_data(cook_role_codes)
        iiko_salary = staff.get("avg_salary", 0)
        iiko_cook_count = staff.get("count", 0)

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –¥–∞–Ω–Ω—ã–µ –∏–∑ iiko ‚Üí —Ñ–æ–ª–±—ç–∫ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        effective_salary = iiko_salary if iiko_salary > 0 else cook_salary
        effective_cooks = iiko_cook_count if iiko_cook_count > 0 else cooks_per_shift

        lines = [f"üìä === –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ö–£–•–ù–ò ({date_from} ‚Äî {date_to}) ==="]

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–≤–∞—Ä–æ–≤
        if staff.get("cooks"):
            lines.append(f"\n=== –ü–û–í–ê–†–ê –ò–ó IIKO ({iiko_cook_count} —á–µ–ª.) ===")
            for c in staff["cooks"]:
                salary_str = f"{c['salary']:.0f} —Ä—É–±." if c["salary"] > 0 else "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                lines.append(f"  {c['name']} | —Ä–æ–ª—å: {c['role']} | –∑–∞—Ä–ø–ª–∞—Ç–∞: {salary_str}")
            if iiko_salary > 0:
                lines.append(f"  –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –∑–∞ —Å–º–µ–Ω—É: {iiko_salary:.0f} —Ä—É–±. (–∏—Å—Ç–æ—á–Ω–∏–∫: {staff['source']})")
            else:
                lines.append(f"  ‚ö†Ô∏è –ó–∞—Ä–ø–ª–∞—Ç–∞ –≤ iiko –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        elif not staff.get("error"):
            lines.append(f"\n‚ö†Ô∏è –ü–æ–≤–∞—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ iiko (–¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–ª—è: {', '.join(staff.get('available_fields', [])[:15])})")

        # ‚îÄ‚îÄ‚îÄ –î–∞–Ω–Ω—ã–µ –ø–æ –ø–æ–≤–∞—Ä–∞–º (–µ—Å–ª–∏ –µ—Å—Ç—å) ‚îÄ‚îÄ‚îÄ
        cook_rows = data.get("cook_rows", [])
        cook_field = data.get("cook_field", "")
        if cook_rows:
            lines.append("\n=== –í–´–†–ê–ë–û–¢–ö–ê –ü–û –ü–û–í–ê–†–ê–ú ===")
            for row in sorted(cook_rows, key=lambda x: float(x.get("DishAmountInt") or x.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0), reverse=True):
                name = row.get(cook_field) or row.get("–ü–æ–≤–∞—Ä") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
                lines.append(f"  {name} | {qty:.0f} –±–ª—é–¥ | {revenue:.0f} —Ä—É–±.")

        # –ü–æ –ø–æ–≤–∞—Ä—É + –∫–∞—Ç–µ–≥–æ—Ä–∏—è –±–ª—é–¥
        cook_dish_rows = data.get("cook_dish_rows", [])
        if cook_dish_rows:
            lines.append("\n=== –ü–û–í–ê–†–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú –ë–õ–Æ–î ===")
            cook_groups = defaultdict(list)
            for row in cook_dish_rows:
                name = row.get(cook_field) or row.get("–ü–æ–≤–∞—Ä") or "?"
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishSumInt") or row.get("–°—É–º–º–∞ –±–µ–∑ —Å–∫–∏–¥–∫–∏") or 0)
                cook_groups[name].append({"group": group, "qty": qty, "revenue": revenue})
            for name, items in cook_groups.items():
                lines.append(f"  {name}:")
                for item in sorted(items, key=lambda x: x["qty"], reverse=True)[:10]:
                    lines.append(f"    {item['group']} | {item['qty']:.0f} —à—Ç | {item['revenue']:.0f} —Ä—É–±.")

        # –ü–æ –ø–æ–≤–∞—Ä—É + –¥–µ–Ω—å
        cook_day_rows = data.get("cook_day_rows", [])
        if cook_day_rows:
            lines.append("\n=== –î–ò–ù–ê–ú–ò–ö–ê –ü–û–í–ê–†–û–í –ü–û –î–ù–Ø–ú ===")
            cook_days = defaultdict(list)
            for row in cook_day_rows:
                name = row.get(cook_field) or row.get("–ü–æ–≤–∞—Ä") or "?"
                day = row.get("OpenDate.Typed") or row.get("–£—á–µ—Ç–Ω—ã–π –¥–µ–Ω—å") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                cook_days[name].append({"day": day, "qty": qty})
            for name, days in cook_days.items():
                day_strs = [f"{d['day']}: {d['qty']:.0f}" for d in sorted(days, key=lambda x: x["day"])]
                lines.append(f"  {name}: {', '.join(day_strs)}")

        # ‚îÄ‚îÄ‚îÄ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–ª—é–¥ (–∫—É—Ö–Ω—è vs –±–∞—Ä) ‚îÄ‚îÄ‚îÄ
        dish_group_rows = data.get("dish_group_rows", [])
        if dish_group_rows:
            lines.append("\n=== –í–´–†–ê–ë–û–¢–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú –ë–õ–Æ–î ===")
            kitchen_total_qty = 0
            kitchen_total_rev = 0
            bar_total_qty = 0
            bar_total_rev = 0
            kitchen_groups = []
            for row in dish_group_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
                if self._is_bar_group(group):
                    bar_total_qty += qty
                    bar_total_rev += revenue
                else:
                    kitchen_total_qty += qty
                    kitchen_total_rev += revenue
                    kitchen_groups.append({"group": group, "qty": qty, "revenue": revenue})

            lines.append(f"  –ö–£–•–ù–Ø –∏—Ç–æ–≥–æ: {kitchen_total_qty:.0f} –±–ª—é–¥, {kitchen_total_rev:.0f} —Ä—É–±.")
            lines.append(f"  –ë–ê–† –∏—Ç–æ–≥–æ: {bar_total_qty:.0f} –ø–æ–∑–∏—Ü–∏–π, {bar_total_rev:.0f} —Ä—É–±.")
            lines.append("  –ö—É—Ö–Ω—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for g in sorted(kitchen_groups, key=lambda x: x["revenue"], reverse=True):
                lines.append(f"    {g['group']} | {g['qty']:.0f} —à—Ç | {g['revenue']:.0f} —Ä—É–±.")

        # ‚îÄ‚îÄ‚îÄ –ù–∞–≥—Ä—É–∑–∫–∞ –∫—É—Ö–Ω–∏ –ø–æ —á–∞—Å–∞–º ‚îÄ‚îÄ‚îÄ
        dish_hour_rows = data.get("dish_hour_rows", [])
        if dish_hour_rows:
            lines.append("\n=== –ù–ê–ì–†–£–ó–ö–ê –ö–£–•–ù–ò –ü–û –ß–ê–°–ê–ú ===")
            hour_stats = defaultdict(lambda: {"qty": 0, "revenue": 0})
            for row in dish_hour_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                if self._is_bar_group(group):
                    continue
                hour = row.get("HourOpen") or row.get("–ß–∞—Å –æ—Ç–∫—Ä—ã—Ç–∏—è") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishSumInt") or row.get("–°—É–º–º–∞ –±–µ–∑ —Å–∫–∏–¥–∫–∏") or 0)
                hour_stats[hour]["qty"] += qty
                hour_stats[hour]["revenue"] += revenue
            for h in sorted(hour_stats.keys()):
                s = hour_stats[h]
                bar = "‚ñà" * min(int(s["qty"] / 5), 30) if s["qty"] > 0 else ""
                lines.append(f"  {h}:00 | {s['qty']:.0f} –±–ª—é–¥ | {s['revenue']:.0f} —Ä—É–±. {bar}")

        # ‚îÄ‚îÄ‚îÄ –¢–æ–ø –∫—É—Ö–æ–Ω–Ω—ã—Ö –±–ª—é–¥ ‚îÄ‚îÄ‚îÄ
        dish_detail_rows = data.get("dish_detail_rows", [])
        if dish_detail_rows:
            lines.append("\n=== –¢–û–ü –ö–£–•–û–ù–ù–´–• –ë–õ–Æ–î ===")
            kitchen_dishes = []
            for row in dish_detail_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                if self._is_bar_group(group):
                    continue
                name = row.get("DishName") or row.get("–ë–ª—é–¥–æ") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
                kitchen_dishes.append({"name": name, "group": group, "qty": qty, "revenue": revenue})
            for d in sorted(kitchen_dishes, key=lambda x: x["qty"], reverse=True)[:25]:
                lines.append(f"  {d['name']} | {d['qty']:.0f} —à—Ç | {d['revenue']:.0f} —Ä—É–±. | {d['group']}")

        # ‚îÄ‚îÄ‚îÄ –ö—É—Ö–æ–Ω–Ω—ã–µ —Å—Ç–∞–Ω—Ü–∏–∏ (CookingPlace) ‚îÄ‚îÄ‚îÄ
        cooking_place_rows = data.get("cooking_place_rows", [])
        if cooking_place_rows:
            lines.append("\n=== –ö–£–•–û–ù–ù–´–ï –°–¢–ê–ù–¶–ò–ò ===")
            for row in sorted(cooking_place_rows, key=lambda x: float(x.get("DishAmountInt") or 0), reverse=True):
                place = row.get("CookingPlace") or row.get("–ú–µ—Å—Ç–æ –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è") or "?"
                qty = float(row.get("DishAmountInt") or 0)
                revenue = float(row.get("DishSumInt") or 0)
                cook_dur = row.get("Cooking.CookingDuration.Avg") or row.get("–°—Ä. –≤—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏") or ""
                kitchen_time = row.get("Cooking.KitchenTime.Avg") or row.get("–°—Ä. –≤—Ä–µ–º—è –Ω–∞ –∫—É—Ö–Ω–µ") or ""
                wait_time = row.get("Cooking.GuestWaitTime.Avg") or row.get("–°—Ä. –æ–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Å—Ç—è") or ""
                time_parts = []
                if cook_dur:
                    time_parts.append(f"–≥–æ—Ç–æ–≤–∫–∞: {cook_dur}")
                if kitchen_time:
                    time_parts.append(f"–∫—É—Ö–Ω—è: {kitchen_time}")
                if wait_time:
                    time_parts.append(f"–æ–∂–∏–¥–∞–Ω–∏–µ: {wait_time}")
                time_str = " | ".join(time_parts) if time_parts else ""
                lines.append(f"  {place} | {qty:.0f} –±–ª—é–¥ | {revenue:.0f} —Ä—É–±. | {time_str}")

        # ‚îÄ‚îÄ‚îÄ –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ‚îÄ‚îÄ‚îÄ
        cooking_time_rows = data.get("cooking_time_rows", [])
        if cooking_time_rows:
            lines.append("\n=== –í–†–ï–ú–Ø –ì–û–¢–û–í–ö–ò –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú ===")
            for row in cooking_time_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                if self._is_bar_group(group):
                    continue
                qty = float(row.get("DishAmountInt") or 0)
                cook_dur = row.get("Cooking.CookingDuration.Avg") or ""
                kitchen_time = row.get("Cooking.KitchenTime.Avg") or ""
                serve_time = row.get("Cooking.ServeTime.Avg") or ""
                late_time = row.get("Cooking.CookingLateTime.Avg") or ""
                parts = [f"{group}: {qty:.0f} –±–ª—é–¥"]
                if cook_dur:
                    parts.append(f"–≥–æ—Ç–æ–≤–∫–∞ {cook_dur}")
                if kitchen_time:
                    parts.append(f"–∫—É—Ö–Ω—è {kitchen_time}")
                if serve_time:
                    parts.append(f"–ø–æ–¥–∞—á–∞ {serve_time}")
                if late_time:
                    parts.append(f"–æ–ø–æ–∑–¥–∞–Ω–∏—è {late_time}")
                lines.append(f"  {' | '.join(parts)}")

        # ‚îÄ‚îÄ‚îÄ –ù–∞–≥—Ä—É–∑–∫–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º ‚îÄ‚îÄ‚îÄ
        cooking_hour_rows = data.get("cooking_hour_rows", [])
        if cooking_hour_rows:
            lines.append("\n=== –°–ö–û–†–û–°–¢–¨ –ö–£–•–ù–ò –ü–û –ß–ê–°–ê–ú ===")
            for row in sorted(cooking_hour_rows, key=lambda x: x.get("HourOpen") or x.get("–ß–∞—Å –æ—Ç–∫—Ä—ã—Ç–∏—è") or ""):
                hour = row.get("HourOpen") or row.get("–ß–∞—Å –æ—Ç–∫—Ä—ã—Ç–∏—è") or "?"
                qty = float(row.get("DishAmountInt") or 0)
                orders = float(row.get("UniqOrderId.OrdersCount") or 0)
                cook_dur = row.get("Cooking.CookingDuration.Avg") or ""
                wait_time = row.get("Cooking.GuestWaitTime.Avg") or ""
                parts = [f"{hour}:00 | {qty:.0f} –±–ª—é–¥ | {orders:.0f} –∑–∞–∫–∞–∑–æ–≤"]
                if cook_dur:
                    parts.append(f"–≥–æ—Ç–æ–≤–∫–∞ {cook_dur}")
                if wait_time:
                    parts.append(f"–æ–∂–∏–¥–∞–Ω–∏–µ {wait_time}")
                lines.append(f"  {' | '.join(parts)}")

        # ‚îÄ‚îÄ‚îÄ –û–±—â–∏–µ –∏—Ç–æ–≥–∏ ‚îÄ‚îÄ‚îÄ
        day_rows = data.get("day_rows", [])
        num_days = len(day_rows) if day_rows else 1
        if day_rows:
            lines.append("\n=== –û–ë–©–ò–ï –ò–¢–û–ì–ò –ü–û –î–ù–Ø–ú ===")
            total_qty = 0
            total_orders = 0
            total_revenue = 0
            for row in day_rows:
                day = row.get("OpenDate.Typed") or row.get("–£—á–µ—Ç–Ω—ã–π –¥–µ–Ω—å") or "?"
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                orders = float(row.get("UniqOrderId.OrdersCount") or row.get("–ó–∞–∫–∞–∑–æ–≤") or 0)
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or 0)
                total_qty += qty
                total_orders += orders
                total_revenue += revenue
                lines.append(f"  {day} | {qty:.0f} –±–ª—é–¥ | {orders:.0f} –∑–∞–∫–∞–∑–æ–≤ | {revenue:.0f} —Ä—É–±.")
            lines.append(f"  –ò–¢–û–ì–û: {total_qty:.0f} –±–ª—é–¥, {total_orders:.0f} –∑–∞–∫–∞–∑–æ–≤, {total_revenue:.0f} —Ä—É–±.")
            if total_orders > 0:
                lines.append(f"  –°—Ä–µ–¥–Ω–µ–µ –±–ª—é–¥ –Ω–∞ –∑–∞–∫–∞–∑: {total_qty / total_orders:.1f}")
            if num_days > 0:
                lines.append(f"  –°—Ä–µ–¥–Ω–µ–µ –±–ª—é–¥ –≤ –¥–µ–Ω—å: {total_qty / num_days:.0f}")

        # ‚îÄ‚îÄ‚îÄ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –¢–†–£–î–ê –ü–û–í–ê–†–û–í ‚îÄ‚îÄ‚îÄ
        # –§–æ—Ä–º—É–ª–∞: –í—ã—Ä—É—á–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ / –ü–æ–≤–∞—Ä–æ–≤ –≤ —Å–º–µ–Ω—É / –ó–∞—Ä–ø–ª–∞—Ç–∞ –∑–∞ —Å–º–µ–Ω—É
        dish_group_rows = data.get("dish_group_rows", [])
        if effective_cooks > 0 and effective_salary > 0 and dish_group_rows:
            salary_source = "iiko" if iiko_salary > 0 else "–∫–æ–Ω—Ñ–∏–≥ (.env)"
            cooks_source = f"iiko, —Ä–æ–ª—å {cook_role_codes}" if iiko_cook_count > 0 else "–∫–æ–Ω—Ñ–∏–≥ (.env)"

            lines.append("\n=== –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –¢–†–£–î–ê –ü–û–í–ê–†–û–í ===")
            lines.append(f"  –ü–æ–≤–∞—Ä–æ–≤ –≤ —Å–º–µ–Ω–µ: {effective_cooks} (–∏—Å—Ç–æ—á–Ω–∏–∫: {cooks_source})")
            lines.append(f"  –ó–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ–≤–∞—Ä–∞ –∑–∞ —Å–º–µ–Ω—É: {effective_salary:.0f} —Ä—É–±. (–∏—Å—Ç–æ—á–Ω–∏–∫: {salary_source})")
            lines.append(f"  –†–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –≤ –ø–µ—Ä–∏–æ–¥–µ: {num_days}")
            lines.append("")

            # –°–æ–±–∏—Ä–∞–µ–º –∫—É—Ö–æ–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            kitchen_groups_prod = []
            kitchen_rev_total = 0
            for row in dish_group_rows:
                group = row.get("DishGroup") or row.get("–ì—Ä—É–ø–ø–∞ –±–ª—é–¥–∞") or "?"
                if self._is_bar_group(group):
                    continue
                revenue = float(row.get("DishDiscountSumInt") or row.get("–°—É–º–º–∞ —Å–æ —Å–∫–∏–¥–∫–æ–π") or row.get("DishSumInt") or 0)
                qty = float(row.get("DishAmountInt") or row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª—é–¥") or 0)
                kitchen_groups_prod.append({"group": group, "revenue": revenue, "qty": qty})
                kitchen_rev_total += revenue

            # –†–∞—Å—á—ë—Ç –ø–æ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            salary_total_per_day = effective_cooks * effective_salary
            lines.append("  –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∫—É—Ö–Ω–∏ (–∑–∞ –¥–µ–Ω—å):")
            for g in sorted(kitchen_groups_prod, key=lambda x: x["revenue"], reverse=True):
                daily_rev = g["revenue"] / num_days
                per_cook = daily_rev / effective_cooks
                coeff = per_cook / effective_salary
                lines.append(
                    f"    {g['group']}: "
                    f"{daily_rev:.0f} —Ä—É–±./–¥–µ–Ω—å ‚Üí "
                    f"{per_cook:.0f} —Ä—É–±./–ø–æ–≤–∞—Ä ‚Üí "
                    f"–∫–æ—ç—Ñ—Ñ. {coeff:.2f}"
                )

            # –ò—Ç–æ–≥–æ –ø–æ –≤—Å–µ–π –∫—É—Ö–Ω–µ
            daily_total = kitchen_rev_total / num_days
            per_cook_total = daily_total / effective_cooks
            coeff_total = per_cook_total / effective_salary
            lines.append("")
            lines.append(f"  –ò–¢–û–ì–û –ö–£–•–ù–Ø –∑–∞ –¥–µ–Ω—å: {daily_total:.0f} —Ä—É–±.")
            lines.append(f"  –í—ã—Ä—É—á–∫–∞ –Ω–∞ 1 –ø–æ–≤–∞—Ä–∞: {per_cook_total:.0f} —Ä—É–±.")
            lines.append(f"  –§–û–¢ –ø–æ–≤–∞—Ä–æ–≤ –∑–∞ –¥–µ–Ω—å: {salary_total_per_day:.0f} —Ä—É–±.")
            lines.append(f"  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {coeff_total:.2f}")
            lines.append(f"  (–≤—ã—Ä—É—á–∫–∞ –Ω–∞ –ø–æ–≤–∞—Ä–∞ / –∑–∞—Ä–ø–ª–∞—Ç–∞ –∑–∞ —Å–º–µ–Ω—É)")
            if coeff_total >= 3:
                lines.append(f"  –û—Ü–µ–Ω–∫–∞: –û–¢–õ–ò–ß–ù–û ‚Äî –ø–æ–≤–∞—Ä–∞ –æ–∫—É–ø–∞—é—Ç—Å—è –≤ {coeff_total:.1f}x")
            elif coeff_total >= 2:
                lines.append(f"  –û—Ü–µ–Ω–∫–∞: –•–û–†–û–®–û ‚Äî –ø–æ–≤–∞—Ä–∞ –æ–∫—É–ø–∞—é—Ç—Å—è –≤ {coeff_total:.1f}x")
            elif coeff_total >= 1:
                lines.append(f"  –û—Ü–µ–Ω–∫–∞: –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û ‚Äî –æ–∫—É–ø–∞–µ–º–æ—Å—Ç—å {coeff_total:.1f}x")
            else:
                lines.append(f"  –û—Ü–µ–Ω–∫–∞: –ù–ò–ó–ö–ê–Ø ‚Äî –ø–æ–≤–∞—Ä–∞ –Ω–µ –æ–∫—É–ø–∞—é—Ç —Å–≤–æ—é –∑–∞—Ä–ø–ª–∞—Ç—É ({coeff_total:.1f}x)")

        else:
            lines.append("\n=== –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –¢–†–£–î–ê ===")
            missing = []
            if effective_cooks <= 0:
                missing.append("–∫–æ–ª-–≤–æ –ø–æ–≤–∞—Ä–æ–≤ (COOKS_PER_SHIFT –∏–ª–∏ COOK_ROLE_CODES)")
            if effective_salary <= 0:
                missing.append("–∑–∞—Ä–ø–ª–∞—Ç–∞ (–∏–∑ iiko –∏–ª–∏ COOK_SALARY_PER_SHIFT)")
            lines.append(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî {', '.join(missing)}")
            lines.append("  –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≤ .env:")
            lines.append("    COOK_ROLE_CODES=–ü–û–í–ê–†,–°–£-–®–ï–§    # —Ä–æ–ª–∏ –ø–æ–≤–∞—Ä–æ–≤ –≤ iiko")
            lines.append("    COOKS_PER_SHIFT=3                # –∏–ª–∏ –≤—Ä—É—á–Ω—É—é –∫–æ–ª-–≤–æ")
            lines.append("    COOK_SALARY_PER_SHIFT=3000       # —Ñ–æ–ª–±—ç–∫ –µ—Å–ª–∏ –Ω–µ—Ç –≤ iiko")

        return "\n".join(lines)

    async def test_connection(self) -> str:
        """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        try:
            await self._ensure_token()
            return f"‚úÖ iikoServer –ø–æ–¥–∫–ª—é—á—ë–Ω ({self.server_url})"
        except Exception as e:
            return f"‚ùå iikoServer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}"

    async def close(self):
        await self.client.aclose()
